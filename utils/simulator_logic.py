import numpy as np
import random
import pandas as pd

def calculate_ema(values, span):
    values = np.array(values, dtype=float)
    if len(values) == 0:
        return np.array([])
    alpha = 2 / (span + 1)
    ema = np.zeros_like(values)
    ema[0] = values[0]
    for i in range(1, len(values)):
        ema[i] = alpha * values[i] + (1 - alpha) * ema[i-1]
    return ema

def calculate_macd(close_prices, fast_period=12, slow_period=26, signal_period=9):
    values = np.array(close_prices, dtype=float)
    if len(values) == 0:
        return {'dif': [], 'dea': [], 'hist': []}
        
    ema_fast = calculate_ema(values, fast_period)
    ema_slow = calculate_ema(values, slow_period)
    
    dif = ema_fast - ema_slow
    dea = calculate_ema(dif, signal_period)
    hist = (dif - dea) * 2
    
    return {
        'dif': dif.tolist(),
        'dea': dea.tolist(),
        'hist': hist.tolist()
    }

def calculate_rsi(prices, period=14):
    """
    è®¡ç®—RSI
    """
    prices = pd.Series(prices)
    if len(prices) < period + 1:
        return [50.0] * len(prices)
        
    delta = prices.diff()
    up = delta.clip(lower=0)
    down = -1 * delta.clip(upper=0)
    
    ma_up = up.ewm(com=period-1, adjust=False).mean()
    ma_down = down.ewm(com=period-1, adjust=False).mean()
    
    rs = ma_up / ma_down
    rsi = 100 - (100 / (1 + rs))
    return rsi.fillna(50.0).tolist()

def calculate_bollinger_bands(prices, period=20, num_std=2):
    """
    è®¡ç®—å¸ƒæ—çº¿
    """
    prices = pd.Series(prices)
    if len(prices) < period:
        return {
            'upper': prices.tolist(),
            'middle': prices.tolist(),
            'lower': prices.tolist()
        }
        
    middle = prices.rolling(window=period).mean()
    std = prices.rolling(window=period).std()
    upper = middle + (std * num_std)
    lower = middle - (std * num_std)
    
    return {
        'upper': upper.fillna(0).tolist(),
        'middle': middle.fillna(0).tolist(),
        'lower': lower.fillna(0).tolist()
    }


def generate_simulation_data(initial_price=100, length=300):
    """
    ç”Ÿæˆæ¨¡æ‹Ÿçš„Kçº¿æ•°æ®
    """
    data = []
    # ç¡®ä¿åˆå§‹ä»·æ ¼åœ¨åˆç†èŒƒå›´å†… (1~1000)
    initial_price = max(5.0, min(950.0, float(initial_price)))
    price = initial_price
    trend = 0  # è¶‹åŠ¿å› å­ (ç™¾åˆ†æ¯”)
    days_until_change = 0 # è·ç¦»ä¸‹æ¬¡å˜ç›˜çš„å¤©æ•°

    for i in range(length):
        # 1. ç¡®å®šä»Šæ—¥æ¶¨è·Œåœé™åˆ¶ (æ˜¨æ”¶ * 1.1 / 0.9)
        # æ¶¨è·Œå¹…æœ€å¤§ 10%
        limit_up = round(price * 1.10, 2)
        limit_down = round(price * 0.90, 2)
        
        # 2. åªæœ‰åœ¨ä»·æ ¼èŒƒå›´å†… (1~1000) æ‰æœ‰æ•ˆ
        limit_up = min(limit_up, 1000.0)
        limit_down = max(limit_down, 1.0)
        
        # éšæœºæ”¹å˜è¶‹åŠ¿ (åŸºäºçœŸå®å¸‚åœºçš„å˜ç›˜å‘¨æœŸ)
        if days_until_change <= 0: 
            # è¶‹åŠ¿åç½®: æ¯å¤©å€¾å‘æ¶¨/è·Œå¤šå°‘ç™¾åˆ†æ¯” (-1% åˆ° 1%)
            trend = np.random.normal(0, 0.005)
            
            # æ ¹æ®çœŸå®å¸‚åœºè§„å¾‹é€‰æ‹©å‘¨æœŸç±»å‹
            cycle_type = random.choices(
                ['short_strong', 'short_std', 'medium_fib', 'medium_month', 'long'],
                weights=[0.30, 0.35, 0.25, 0.08, 0.02], # æƒé‡ï¼šçŸ­æœŸæ³¢åŠ¨æœ€å¸¸è§ï¼Œä¸­æœŸæ¬¡ä¹‹
                k=1
            )[0]
            
            if cycle_type == 'short_strong':
                # 3-5ä¸ªäº¤æ˜“æ—¥ (å¼ºåŠ¿æ•´ç†å‘¨æœŸ)
                days_until_change = random.randint(3, 5)
            elif cycle_type == 'short_std':
                # 5-9ä¸ªäº¤æ˜“æ—¥ (å¸¸è§çŸ­çº¿æ³¢æ®µ)
                days_until_change = random.randint(5, 9)
            elif cycle_type == 'medium_fib':
                # æ–æ³¢é‚£å¥‘æ—¶é—´çª— (13, 21, 34, 55)ï¼ŒåŠ å°‘é‡éšæœºæ‰°åŠ¨
                base = random.choice([13, 21, 34, 55])
                days_until_change = base + random.randint(-2, 2)
            elif cycle_type == 'medium_month':
                # 1-2ä¸ªæœˆ (å‘¨çº¿çº§åˆ«è°ƒæ•´)
                days_until_change = random.randint(20, 60)
            else:
                # é•¿æœŸ (ç”±äºæ¨¡æ‹Ÿé•¿åº¦é™åˆ¶ï¼Œé€‚å½“ç¼©å°)
                days_until_change = random.randint(60, 100)
        
        days_until_change -= 1 
            
        # 3. ç”Ÿæˆå¼€ç›˜ä»· (Pre-market fluctuation)
        # å¤šæ•°æ—¶å€™å¹³å¼€ï¼Œå¶å°”å°å¹…é«˜å¼€ä½å¼€
        open_shock = np.random.normal(0, 0.005) 
        open_p = price * (1 + open_shock)
        
        # 4. ç”Ÿæˆæ”¶ç›˜ä»· (Day fluctuation based on trend)
        # æ—¥å†…æ³¢åŠ¨ ~2% + è¶‹åŠ¿
        day_change = np.random.normal(0, 0.02) + trend
        close_p = price * (1 + day_change)
        
        # 5. ç”Ÿæˆæœ€é«˜æœ€ä½ (High/Low)
        # åŸºäºopen/close æ‰©å±•
        raw_high = max(open_p, close_p) * (1 + abs(np.random.normal(0, 0.01)))
        raw_low = min(open_p, close_p) * (1 - abs(np.random.normal(0, 0.01)))
        
        # 6. ä¿®æ­£æ‰€æœ‰ä»·æ ¼åˆ°é™åˆ¶èŒƒå›´å†…
        def clamp(val):
            return max(limit_down, min(limit_up, val))
            
        open_p = clamp(open_p)
        close_p = clamp(close_p)
        high_p = clamp(raw_high)
        low_p = clamp(raw_low)
        
        # 7. å†æ¬¡ç¡®ä¿é€»è¾‘ä¸€è‡´æ€§ (H >= max(O,C), L <= min(O,C))
        high_p = max(high_p, open_p, close_p)
        low_p = min(low_p, open_p, close_p)

        data.append({
            'time': i,
            'open': round(open_p, 2),
            'high': round(high_p, 2),
            'low': round(low_p, 2),
            'close': round(close_p, 2)
        })
        
        price = close_p

    # è®¡ç®—MACD
    closes = [d['close'] for d in data]
    macd = calculate_macd(closes)
    
    return data, macd

def identify_fenxing(klines):
    """
    ç®€å•åˆ¤æ–­æœ€å3æ ¹Kçº¿æ˜¯å¦æ„æˆé¡¶åˆ†å‹æˆ–åº•åˆ†å‹
    klines: è‡³å°‘åŒ…å«æœ€å3æ ¹Kçº¿çš„æ•°æ® list of dict
    """
    if len(klines) < 3:
        return None
        
    k1, k2, k3 = klines[-3], klines[-2], klines[-1]
    
    # ç®€å•çš„é¡¶åˆ†å‹å®šä¹‰ï¼šä¸­é—´Kçº¿é«˜ç‚¹æœ€é«˜ï¼Œåº•ä¸æœ€ä½ï¼ˆè¿™é‡Œç®€åŒ–ï¼Œä¸¥è°¨ç¼ è®ºéœ€è¦åŒ…å«å¤„ç†ï¼‰
    # ç¼ è®ºæ ‡å‡†ï¼šé¡¶åˆ†å‹æ˜¯ä¸­æŒ‡æœ€é«˜ç‚¹æœ€é«˜ï¼Œæœ€ä½ç‚¹ä¹Ÿæœ€é«˜ï¼ˆä¸åŒ…å«å…³ç³»åï¼‰
    # è¿™é‡Œæˆ‘ä»¬å‡è®¾å·²ç»ç»è¿‡åŒ…å«å¤„ç†ï¼Œæˆ–è€…ç®€å•åˆ¤æ–­é«˜ä½ç‚¹
    
    is_top = k2['high'] > k1['high'] and k2['high'] > k3['high']
    is_bottom = k2['low'] < k1['low'] and k2['low'] < k3['low']
    
    if is_top: return 'top'
    if is_bottom: return 'bottom'
    return None

def process_baohan(klines_data):
    """
    å¤„ç†Kçº¿åŒ…å«å…³ç³»
    input: list of dict {'time', 'open', 'high', 'low', 'close'}
    output: list of dict (processed)
    """
    if not klines_data:
        return []
        
    processed = []
    # è½¬æ¢æ ¼å¼æ–¹ä¾¿å¤„ç†
    for k in klines_data:
        processed.append({
            'high': float(k['high']), 
            'low': float(k['low']), 
            'date': k.get('time', k.get('date')),
            'original': k
        })
        
    if len(processed) < 2:
        return processed
        
    result = [processed[0]]
    direction = 1 # 1 for up, -1 for down (default up)
    
    for i in range(1, len(processed)):
        curr = processed[i]
        prev = result[-1]
        
        # åˆ¤æ–­åŒ…å«å…³ç³»: (High1 >= High2 and Low1 <= Low2) or (High2 >= High1 and Low2 <= Low1)
        is_included = (prev['high'] >= curr['high'] and prev['low'] <= curr['low']) or \
                      (curr['high'] >= prev['high'] and curr['low'] <= prev['low'])
                      
        if is_included:
            # å¤„ç†åŒ…å«
            if direction == 1: # å‘ä¸Šè¶‹åŠ¿ï¼Œå–é«˜é«˜ï¼Œä½é«˜
                new_high = max(prev['high'], curr['high'])
                new_low = max(prev['low'], curr['low'])
            else: # å‘ä¸‹è¶‹åŠ¿ï¼Œå–ä½ä½ï¼Œé«˜ä½
                new_high = min(prev['high'], curr['high'])
                new_low = min(prev['low'], curr['low'])
            
            # æ›´æ–°å‰ä¸€æ ¹Kçº¿ï¼ˆåˆå¹¶ï¼‰
            result[-1]['high'] = new_high
            result[-1]['low'] = new_low
            # dateé€šå¸¸å–åä¸€æ ¹çš„date
            result[-1]['date'] = curr['date']
            result[-1]['original'] = curr['original'] # Keep reference to latest
            
        else:
            # ç¡®å®šæ–°è¶‹åŠ¿æ–¹å‘ (å¦‚æœä¸æ˜¯åŒ…å«ï¼Œåˆ™ç¡®å®šæ–°æ–¹å‘)
            if curr['high'] > prev['high']:
                direction = 1
            elif curr['low'] < prev['low']:
                direction = -1
            
            result.append(curr)
            
    return result

def find_bi(processed_klines):
    """
    è¯†åˆ«ç¬” (Bi)
    input: processed klines (after inclusion handling)
    output: list of {'type': 'top'/'bottom', 'index': i, 'price': val, 'date': ...}
    """
    if len(processed_klines) < 5:
        return []
        
    fx_list = []
    # 1. Find all FenXing (Fractals)
    for i in range(1, len(processed_klines)-1):
        k1 = processed_klines[i-1]
        k2 = processed_klines[i]
        k3 = processed_klines[i+1]
        
        if k2['high'] > k1['high'] and k2['high'] > k3['high']:
            fx_list.append({'type': 'top', 'index': i, 'price': k2['high'], 'date': k2['date']})
        elif k2['low'] < k1['low'] and k2['low'] < k3['low']:
            fx_list.append({'type': 'bottom', 'index': i, 'price': k2['low'], 'date': k2['date']})
            
    if not fx_list:
        return []
        
    # 2. Connect FenXing to form Bi
    # è§„åˆ™ï¼š
    # a. é¡¶åº•äº¤æ›¿
    # b. ä¸­é—´è‡³å°‘éš”3æ ¹Kçº¿ (index diff >= 4) ? 
    #    æ ‡å‡†ç¼ è®ºï¼šé¡¶åˆ†å‹ä¸åº•åˆ†å‹ä¹‹é—´è‡³å°‘æœ‰ä¸€æ ¹Kçº¿ä¸å±äºè¿™ä¸¤ä¸ªåˆ†å‹ï¼Œå³ index diff >= 3 (e.g. 1(top), 2, 3, 4(bottom)) -> 4-1=3 ?
    #    Strictly: Top(i), Bottom(j) -> j > i+3 (at least 3 K-lines between the peak and valley points? No, between the constituent K-lines)
    #    Simpler rule: Index difference >= 4 (Top is at i, Bottom at j, j-i >= 4)
    
    bi_points = []
    # Find first strong point to start? Or just start from first valid pair
    
    # ç®€å•å›æº¯ç®—æ³•
    # æ‰¾åˆ°æœ€é«˜/æœ€ä½ç‚¹ä½œä¸ºèµ·ç‚¹
    
    last_bi = fx_list[0]
    bi_points.append(last_bi)
    
    for fx in fx_list[1:]:
        if fx['type'] == last_bi['type']:
            # Same type, check if better (higher top or lower bottom)
            if fx['type'] == 'top':
                if fx['price'] > last_bi['price']:
                    bi_points[-1] = fx # Replace with higher top
                    last_bi = fx
            else: # bottom
                if fx['price'] < last_bi['price']:
                    bi_points[-1] = fx # Replace with lower bottom
                    last_bi = fx
        else:
            # Different type, check distance
            if fx['index'] - last_bi['index'] >= 4:
                bi_points.append(fx)
                last_bi = fx
            else:
                # Distance too short, ignore? Or maybe the previous one was wrong?
                # This is complex. Simplified: Ignore current if too close.
                pass
                
    return bi_points

def check_divergence(klines, macd_data, index, lookback=30):
    """
    æ£€æŸ¥èƒŒé©°ï¼Œè¿”å›æè¿°å’Œéœ€è¦é«˜äº®çš„å½¢çŠ¶æ•°æ®
    """
    if index < lookback: return None, []
    
    current_k = klines[index]
    current_hist = macd_data['hist'][index]
    
    # ä»¥å‰ lookback æ ¹Kçº¿ä½œä¸ºå‚è€ƒç³»
    start_lookback = index - lookback
    prev_klines = klines[start_lookback:index]
    prev_hists = macd_data['hist'][start_lookback:index]
    
    if not prev_klines: return None, []

    # ---åº•èƒŒé©°åˆ¤æ–­---
    # æ¡ä»¶1ï¼šåˆ›æ–°ä½
    min_prev_low = float('inf')
    min_prev_idx = -1
    
    for i, k in enumerate(prev_klines):
        if k['low'] < min_prev_low:
            min_prev_low = k['low']
            # i æ˜¯ç›¸å¯¹ prev_klines çš„ç´¢å¼•ï¼Œmin_prev_idx éœ€è¦æ˜¯å…¨å±€ç´¢å¼•
            min_prev_idx = start_lookback + i
            
    if current_k['low'] < min_prev_low:
        # æ¡ä»¶2ï¼šMACDç»¿æŸ±æ²¡æœ‰åˆ›æ–°ä½ (åŠ¨èƒ½è¡°ç«­)
        min_hist_prev = min(prev_hists)
        
        # æ‰¾åˆ°å‰ä½MACDçš„ç´¢å¼•ï¼Œç”¨äºç”»å›¾
        min_hist_idx_rel = prev_hists.index(min_hist_prev)
        min_hist_idx = start_lookback + min_hist_idx_rel
        
        if current_hist < 0 and current_hist > min_hist_prev:
            shapes = [
                # 1. Kçº¿å›¾ï¼šèƒŒé©°è¿çº¿ (åŠ ç²—å®çº¿)
                {
                    'type': 'line',
                    'xref': 'x', 'yref': 'y',
                    'x0': min_prev_idx, 'y0': min_prev_low,
                    'x1': index, 'y1': current_k['low'],
                    'line': {'color': 'rgb(128, 128, 128)', 'width': 3} # ç°è‰²
                },
                # 2. Kçº¿å›¾ï¼šèƒŒé©°åŒºé—´èƒŒæ™¯ (æ·¡çº¢é«˜äº®)
                {
                    'type': 'rect',
                    'xref': 'x', 'yref': 'y',
                    'x0': min_prev_idx,
                    'x1': index,
                    'y0': min(min_prev_low, current_k['low']) * 0.99, # ç¨å¾®æ‰©ä¸€ç‚¹èŒƒå›´
                    'y1': max(min_prev_low, current_k['low']) * 1.01,
                    'fillcolor': 'rgba(254, 202, 202, 0.4)', # Red-200
                    'line': {'width': 0}
                },
                # 3. MACDå›¾ï¼šèƒŒé©°è¿çº¿ (è™šçº¿æŒ‡ç¤º)
                {
                    'type': 'line',
                    'xref': 'x', 'yref': 'y2', # æŒ‡å‘å‰¯å›¾Yè½´
                    'x0': min_hist_idx, 'y0': min_hist_prev,
                    'x1': index, 'y1': current_hist,
                    'line': {'color': 'rgb(128, 128, 128)', 'width': 2, 'dash': 'dot'} 
                }
            ]
            return "åº•èƒŒé©°ï¼ˆä»·æ ¼æ–°ä½ä½†ç»¿æŸ±æœªåŠ æ·±ï¼‰", shapes
            
    # ---é¡¶èƒŒé©°åˆ¤æ–­---
    # æ¡ä»¶1ï¼šåˆ›æ–°é«˜
    max_prev_high = float('-inf')
    max_prev_idx = -1
    
    for i, k in enumerate(prev_klines):
        if k['high'] > max_prev_high:
            max_prev_high = k['high']
            max_prev_idx = start_lookback + i
            
    if current_k['high'] > max_prev_high:
        # æ¡ä»¶2ï¼šMACDçº¢æŸ±æ²¡æœ‰åˆ›æ–°é«˜
        max_hist_prev = max(prev_hists)
        
        # æ‰¾åˆ°å‰é«˜MACDçš„ç´¢å¼•
        max_hist_idx_rel = prev_hists.index(max_hist_prev)
        max_hist_idx = start_lookback + max_hist_idx_rel
        
        if current_hist > 0 and current_hist < max_hist_prev:
            shapes = [
                # 1. Kçº¿å›¾ï¼šèƒŒé©°è¿çº¿ (åŠ ç²—å®çº¿)
                {
                    'type': 'line',
                    'xref': 'x', 'yref': 'y',
                    'x0': max_prev_idx, 'y0': max_prev_high,
                    'x1': index, 'y1': current_k['high'],
                    'line': {'color': 'rgb(128, 128, 128)', 'width': 3} # ç°è‰²
                },
                # 2. Kçº¿å›¾ï¼šèƒŒé©°åŒºé—´èƒŒæ™¯ (æ·¡ç»¿é«˜äº®)
                {
                    'type': 'rect',
                    'xref': 'x', 'yref': 'y',
                    'x0': max_prev_idx,
                    'x1': index,
                    'y0': min(max_prev_high, current_k['high']) * 0.99,
                    'y1': max(max_prev_high, current_k['high']) * 1.01,
                    'fillcolor': 'rgba(187, 247, 208, 0.4)', # Green-200
                    'line': {'width': 0}
                },
                # 3. MACDå›¾ï¼šèƒŒé©°è¿çº¿ (è™šçº¿æŒ‡ç¤º)
                {
                    'type': 'line',
                    'xref': 'x', 'yref': 'y2', # æŒ‡å‘å‰¯å›¾Yè½´
                    'x0': max_hist_idx, 'y0': max_hist_prev,
                    'x1': index, 'y1': current_hist,
                    'line': {'color': 'rgb(128, 128, 128)', 'width': 2, 'dash': 'dot'}
                }
            ]
            return "é¡¶èƒŒé©°ï¼ˆä»·æ ¼æ–°é«˜ä½†çº¢æŸ±æœªå¢é•¿ï¼‰", shapes
            
    return None, []

def resample_klines(daily_data, period):
    """
    å°†æ—¥çº¿æ•°æ®é‡é‡‡æ ·ä¸ºæ›´å¤§çº§åˆ«çš„æ•°æ® (å‘¨K, æœˆKç­‰)
    period: èšåˆçš„Kçº¿æ•°é‡ï¼Œä¾‹å¦‚ 5 (å‘¨), 20 (æœˆ), 60 (å­£)
    """
    resampled = []
    if not daily_data:
        return [], calculate_macd([]) # è¿”å›ç©ºMACDç»“æ„

    # æŒ‰å›ºå®šå‘¨æœŸåˆ†å—
    for i in range(0, len(daily_data), period):
        chunk = daily_data[i : i + period]
        if not chunk: continue
        
        # èšåˆ
        open_p = chunk[0]['open']
        close_p = chunk[-1]['close']
        high_p = max(d['high'] for d in chunk)
        low_p = min(d['low'] for d in chunk)
        
        # ä½¿ç”¨æ–°çš„ç´¢å¼•ä½œä¸ºtime
        new_time = len(resampled)
        
        resampled.append({
            'time': new_time,
            'open': open_p,
            'high': high_p,
            'low': low_p,
            'close': close_p,
            # ä¿ç•™åŸå§‹çš„å¯¹åº”æ—¥çº¿ç´¢å¼•èŒƒå›´ï¼Œç”¨äºUIæ˜ å°„
            'start_day_idx': chunk[0]['time'],
            'end_day_idx': chunk[-1]['time']
        })
        
    # è®¡ç®—æ–°çº§åˆ«çš„MACD
    closes = [d['close'] for d in resampled]
    macd = calculate_macd(closes)
    
    return resampled, macd

def calculate_bi_and_zhongshu_shapes(klines):
    """
    è®¡ç®—å¹¶è¿”å›ç¬”ï¼ˆBiï¼‰å’Œä¸­æ¢ï¼ˆZhongshu/Boxï¼‰çš„å½¢çŠ¶æ•°æ®
    ç®€åŒ–ç‰ˆé€»è¾‘ï¼Œä»…ç”¨äºæ¨¡æ‹Ÿå™¨å±•ç¤ºè¾…åŠ©
    """
    shapes = []
    
    # 1. è¯†åˆ«æ‰€æœ‰åˆ†å‹ç‚¹ (Fenxing Points)
    fenxings = [] # list of {'index': i, 'type': 'top'/'bottom', 'val': price}
    
    # è¿™é‡Œéœ€è¦éå†æ•´ä¸ªåºåˆ—æ¥é€šè¿‡äº¤æ›¿è§„åˆ™ç¡®è®¤ç¬”
    # æ³¨æ„ï¼šklines æ˜¯æˆªæ­¢åˆ°å½“å‰çš„å…¨éƒ¨æ•°æ®ï¼Œæˆ‘ä»¬é‡æ–°è®¡ç®—æ•´ä¸ªå†å²çš„ç¬”
    for i in range(2, len(klines)):
        subset = klines[i-2 : i+1]
        fx_type = identify_fenxing(subset)
        if fx_type:
            # ç®€åŒ–ç‰ˆç¬”è¯†åˆ«é€»è¾‘ï¼š
            # 1. å¿…é¡»æ˜¯ä¸€é¡¶ä¸€åº•äº¤æ›¿
            # 2. é¡¶åº•ä¹‹é—´è‡³å°‘é—´éš”ä¸€å®šKçº¿ (è¿™é‡Œè®¾ä¸º3æ ¹ï¼Œå³ä¸­é—´æœ‰Kçº¿)
            k2 = subset[1]
            # k2çš„ç´¢å¼•åœ¨å…¨å±€åºåˆ—ä¸­æ˜¯ i-1
            k2_idx = i - 1
            val = k2['high'] if fx_type == 'top' else k2['low']
            
            if not fenxings:
                # ç¬¬ä¸€ä¸ªåˆ†å‹ç›´æ¥æ¥çº³
                fenxings.append({'index': k2_idx, 'type': fx_type, 'val': val})
            else:
                last = fenxings[-1]
                if last['type'] != fx_type:
                    # ç±»å‹ä¸åŒï¼Œæ£€æŸ¥è·ç¦»
                    if k2_idx - last['index'] >= 3:
                        fenxings.append({'index': k2_idx, 'type': fx_type, 'val': val})
                    # å¦‚æœè·ç¦»å¤ªè¿‘ï¼Œå¿½ç•¥è¿™ä¸ªæ–°åˆ†å‹ï¼ˆæˆ–è€…è¿™æ˜¯ä¸€ä¸ªæ›´ä¼˜çš„åˆ†å‹ï¼Ÿï¼‰
                    # ç®€åŒ–å¤„ç†ï¼šå¿½ç•¥è¿‡è¿‘çš„è½¬æŠ˜
                else:
                    # ç±»å‹ç›¸åŒï¼Œä¿ç•™æ›´æç«¯çš„é‚£ä¸ª
                    if fx_type == 'top':
                        if val > last['val']:
                            fenxings[-1] = {'index': k2_idx, 'type': fx_type, 'val': val}
                    else:
                        if val < last['val']:
                            fenxings[-1] = {'index': k2_idx, 'type': fx_type, 'val': val}

    # 2. ç”Ÿæˆç¬”çš„è¿çº¿ (Bi Shapes)
    bi_segments = [] 
    for i in range(len(fenxings) - 1):
        p1 = fenxings[i]
        p2 = fenxings[i+1]
        
        shapes.append({
            'type': 'line',
            'xref': 'x', 'yref': 'y',
            'x0': p1['index'], 'y0': p1['val'],
            'x1': p2['index'], 'y1': p2['val'],
            'line': {'color': 'rgba(70, 70, 70, 0.6)', 'width': 2}, # æ·±ç°è‰²å®çº¿
            # 'layer': 'below' # Plotly shape layer (not supported directly in dict always, simplified)
        })
        bi_segments.append({
            'x0': p1['index'], 'y0': p1['val'],
            'x1': p2['index'], 'y1': p2['val']
        })

    # 3. ç”Ÿæˆä¸­æ¢çŸ©å½¢ (Zhongshu Shapes)
    # é€»è¾‘ï¼šè¿ç»­ä¸‰ç¬”é‡å éƒ¨åˆ† -> å‡çº§é€»è¾‘ï¼šåˆå¹¶é‡å /è¿ç»­çš„ä¸­æ¢ä¸ºå¤§çº§åˆ«ä¸­æ¢
    raw_zhongshus = []
    if len(bi_segments) >= 3:
        for i in range(len(bi_segments) - 2):
            b1 = bi_segments[i]
            b2 = bi_segments[i+1]
            b3 = bi_segments[i+2]
            
            # è®¡ç®—ä¸‰ç¬”ä»·æ ¼åŒºé—´çš„äº¤é›† (ä¸­æ¢æ ¸å¿ƒåŒºåŸŸ)
            r1 = (min(b1['y0'], b1['y1']), max(b1['y0'], b1['y1']))
            r2 = (min(b2['y0'], b2['y1']), max(b2['y0'], b2['y1']))
            r3 = (min(b3['y0'], b3['y1']), max(b3['y0'], b3['y1']))
            
            overlap_min = max(r1[0], r2[0], r3[0])
            overlap_max = min(r1[1], r2[1], r3[1])
            
            if overlap_min < overlap_max:
                # å­˜åœ¨æœ‰æ•ˆä¸­æ¢åŒºåŸŸ
                raw_zhongshus.append({
                    'x0': b1['x0'], 
                    'x1': b3['x1'],
                    'y0': overlap_min,
                    'y1': overlap_max
                })

    # åˆå¹¶é‡å çš„ä¸­æ¢ (Expansion/Extension)
    merged_zhongshus = []
    if raw_zhongshus:
        # æŒ‰å¼€å§‹æ—¶é—´æ’åº (é€šå¸¸å·²ç»æ˜¯é¡ºåºçš„)
        current_z = raw_zhongshus[0]
        
        for i in range(1, len(raw_zhongshus)):
            next_z = raw_zhongshus[i]
            
            # åˆ¤æ–­æ˜¯å¦é‡å  (Overlap)
            # 1. æ—¶é—´ä¸Šï¼šraw_zhongshus æ˜¯åŸºäºæ»‘åŠ¨çª—å£ç”Ÿæˆçš„ï¼Œå¤©ç”Ÿæ—¶é—´é‡å /è¿ç»­
            # 2. ç©ºé—´ä¸Šï¼šåˆ¤æ–­ä»·æ ¼åŒºé—´æ˜¯å¦æœ‰äº¤é›†
            mn = max(current_z['y0'], next_z['y0'])
            mx = min(current_z['y1'], next_z['y1'])
            
            if mn < mx:
                # å­˜åœ¨ä»·æ ¼äº¤é›†ï¼Œè§†ä¸ºåŒä¸€ä¸­æ¢çš„å»¶ä¼¸/æ‰©å¼  -> åˆå¹¶
                # æ–°çš„èŒƒå›´ï¼šæ—¶é—´å¹¶é›†ï¼Œä»·æ ¼å¹¶é›† (ä½“ç°å¤§çº§åˆ«/æ‰©å¼ èŒƒå›´)
                # æ³¨ï¼šç¼ è®ºä¸¥æ ¼å®šä¹‰ä¸­æ¢çº§åˆ«å‡çº§éœ€è¦9æ®µï¼Œæˆ–è€…ä¸¤ä¸ªç‹¬ç«‹ä¸­æ¢æ³¢åŠ¨åŒºé—´é‡å ã€‚
                # è¿™é‡Œåšè§†è§‰ç®€åŒ–ï¼šå‡¡æ˜¯è¿åœ¨ä¸€èµ·ä¸”ä»·æ ¼é‡å çš„ï¼Œéƒ½ç”»æˆä¸€ä¸ªå¤§æ¡†ã€‚
                current_z['x1'] = max(current_z['x1'], next_z['x1'])
                current_z['y0'] = min(current_z['y0'], next_z['y0'])
                current_z['y1'] = max(current_z['y1'], next_z['y1'])
            else:
                # ä¸é‡å ï¼Œç»“æŸå½“å‰ä¸­æ¢ï¼Œå¼€å§‹ä¸‹ä¸€ä¸ª
                merged_zhongshus.append(current_z)
                current_z = next_z
        
        merged_zhongshus.append(current_z)

    # ç”Ÿæˆæœ€ç»ˆå½¢çŠ¶
    for z in merged_zhongshus:
        shapes.append({
            'type': 'rect',
            'xref': 'x', 'yref': 'y',
            'x0': z['x0'], 
            'x1': z['x1'],
            'y0': z['y0'],
            'y1': z['y1'],
            'fillcolor': 'rgba(255, 165, 0, 0.15)', # æ©™è‰²åŠé€æ˜
            'line': {'width': 0},
        })
        # ç”»è¾¹æ¡†
        shapes.append({
             'type': 'rect',
             'xref': 'x', 'yref': 'y',
             'x0': z['x0'], 
             'x1': z['x1'],
             'y0': z['y0'],
             'y1': z['y1'],
             'line': {'color': 'rgba(255, 165, 0, 0.6)', 'width': 1.5, 'dash': 'dot'}, # åŠ ç²—ä¸€ç‚¹è¾¹æ¡†
             'fillcolor': 'rgba(0,0,0,0)'
        })

    return shapes

def calculate_bi_and_centers(klines):
    """
    è®¡ç®—ç¬”å’Œä¸­æ¢ï¼Œè¿”å›ç»“æ„åŒ–æ•°æ®ï¼ˆéå›¾å½¢Shapesï¼‰
    """
    # 1. è¯†åˆ«åˆ†å‹
    fenxings = []
    for i in range(2, len(klines)):
        subset = klines[i-2 : i+1]
        fx_type = identify_fenxing(subset)
        if fx_type:
            k2 = subset[1]
            k2_idx = i - 1
            val = k2['high'] if fx_type == 'top' else k2['low']
            date = k2.get('date', '')
            
            if not fenxings:
                fenxings.append({'index': k2_idx, 'type': fx_type, 'val': val, 'date': date})
            else:
                last = fenxings[-1]
                if last['type'] != fx_type:
                    if k2_idx - last['index'] >= 3:
                        fenxings.append({'index': k2_idx, 'type': fx_type, 'val': val, 'date': date})
                else:
                    if fx_type == 'top':
                        if val > last['val']:
                            fenxings[-1] = {'index': k2_idx, 'type': fx_type, 'val': val, 'date': date}
                    else:
                        if val < last['val']:
                            fenxings[-1] = {'index': k2_idx, 'type': fx_type, 'val': val, 'date': date}
                            
    # 2. ç”Ÿæˆç¬”
    bi_list = []
    for i in range(len(fenxings) - 1):
        p1 = fenxings[i]
        p2 = fenxings[i+1]
        bi_list.append({
            'start_index': p1['index'],
            'start_val': p1['val'],
            'start_date': p1['date'],
            'end_index': p2['index'],
            'end_val': p2['val'],
            'end_date': p2['date'],
            'type': 'up' if p2['val'] > p1['val'] else 'down'
        })
        
    # 3. ç”Ÿæˆä¸­æ¢
    centers = []
    if len(bi_list) >= 3:
        raw_centers = []
        for i in range(len(bi_list) - 2):
            b1 = bi_list[i]
            b2 = bi_list[i+1]
            b3 = bi_list[i+2]
            
            min1, max1 = min(b1['start_val'], b1['end_val']), max(b1['start_val'], b1['end_val'])
            min2, max2 = min(b2['start_val'], b2['end_val']), max(b2['start_val'], b2['end_val'])
            min3, max3 = min(b3['start_val'], b3['end_val']), max(b3['start_val'], b3['end_val'])
            
            zg = min(max1, max2, max3)
            zd = max(min1, min2, min3)
            
            if zg > zd:
                raw_centers.append({
                    'start_index': b1['end_index'], # é€»è¾‘èµ·ç‚¹è°ƒæ•´ä¸º b1 çš„ç»“æŸï¼ˆå³ b2 çš„å¼€å§‹ï¼‰ï¼Œå»é™¤è¿›å…¥ç¬”
                    'end_index': b3['end_index'], 
                    'visual_end_index': b2['end_index'], 
                    'start_date': b1['end_date'], # å¯¹åº” b2.start_date
                    'end_date': b3['end_date'],
                    'visual_end_date': b2['end_date'],
                    'zg': zg,
                    'zd': zd,
                    'is_up': b1['type'] == 'up' # è®°å½•æ–¹å‘ï¼Œåç»­å¯é€‰ç”¨äºé¢œè‰²åŒºåˆ†
                })
        
        # åˆå¹¶é‡å çš„ä¸­æ¢
        if raw_centers:
            curr = raw_centers[0]
            # é»˜è®¤ä½¿ç”¨ visual_end ä½œä¸ºæ˜¾ç¤ºç»“æŸ
            curr['end_index'] = curr['visual_end_index']
            curr['end_date'] = curr['visual_end_date']
            
            for next_c in raw_centers[1:]:
                mn = max(curr['zd'], next_c['zd'])
                mx = min(curr['zg'], next_c['zg'])
                
                if mn < mx:
                    # åˆå¹¶
                    # åªè¦æœ‰é‡å ï¼Œå°±å»¶ä¼¸åˆ°ä¸‹ä¸€ä¸ªä¸­æ¢çš„è§†è§‰ç»“æŸç‚¹
                    curr['end_index'] = max(curr['end_index'], next_c['visual_end_index'])
                    curr['end_date'] = next_c['visual_end_date'] 
                    
                    # åŒºé—´åˆå¹¶ç­–ç•¥ï¼šå–å¹¶é›†ï¼ˆä¿æŒæœ€å¤§åŒ…å®¹æ€§ï¼‰
                    curr['zd'] = min(curr['zd'], next_c['zd'])
                    curr['zg'] = max(curr['zg'], next_c['zg'])
                else:
                    centers.append(curr)
                    curr = next_c
                    # åˆå§‹åŒ–æ–°ä¸­æ¢çš„ç»“æŸæ—¶é—´
                    curr['end_index'] = curr['visual_end_index']
                    curr['end_date'] = curr['visual_end_date']
            centers.append(curr)
            
    return bi_list, centers

def get_chanlun_shapes(klines, macd_data, current_index):
    """
    è®¡ç®—å¹¶è¿”å›Kçº¿å¯¹åº”çš„ç¬”ã€ä¸­æ¢ã€åˆ†å‹å’ŒèƒŒé©°å½¢çŠ¶
    åŠŸèƒ½é›†æˆï¼Œç”¨äºä»»æ„çº§åˆ«çš„Kçº¿åˆ†æ
    """
    highlight_shapes = []
    
    # 1. ç¬”å’Œä¸­æ¢
    # ä¸ºäº†æ€§èƒ½ï¼Œå¯ä»¥åªè®¡ç®—æœ€è¿‘çš„ä¸€æ®µï¼Œä½†ä¸ºäº†å‡†ç¡®æ€§ï¼Œè¿™é‡Œä¼ å…¥å…¨éƒ¨å†å²ï¼ˆklinesæ˜¯åˆ‡ç‰‡è¿‡çš„ï¼‰
    # åœ¨æ¨¡æ‹Ÿå™¨ä¸­ current_index < 400 å·¦å³ï¼Œè®¡ç®—å¼€é”€å¯æ§
    bi_zhongshu_shapes = calculate_bi_and_zhongshu_shapes(klines)
    highlight_shapes.extend(bi_zhongshu_shapes)
    
    # 2. èƒŒé©°
    divergence_desc, divergence_shapes = check_divergence(klines, macd_data, current_index)
    if divergence_shapes:
        highlight_shapes.extend(divergence_shapes)
    
    # 3. åˆ†å‹ï¼ˆå½“å‰Kçº¿ï¼‰
    recent_k = klines[max(0, current_index-2):current_index+1]
    fenxing = identify_fenxing(recent_k)
    
    if fenxing:
        k_subset = klines[current_index-2 : current_index+1]
        if k_subset:
            max_h = max(k['high'] for k in k_subset)
            min_l = min(k['low'] for k in k_subset)
            
            if fenxing == 'bottom':
                box_color = 'rgba(255, 0, 0, 0.1)' # åçº¢
                border_color = 'rgba(255, 0, 0, 0.5)'
            else:
                box_color = 'rgba(0, 128, 0, 0.1)' # åç»¿
                border_color = 'rgba(0, 128, 0, 0.5)'
            
            highlight_shapes.append({
                'type': 'rect',
                'xref': 'x', 'yref': 'y',
                'x0': current_index - 2 - 0.4, 
                'x1': current_index + 0.4,
                'y0': min_l,
                'y1': max_h,
                'fillcolor': box_color,
                'line': {'color': border_color, 'width': 1, 'dash': 'solid'}
            })
            
    return highlight_shapes

def analyze_action(action, klines, macd_data, current_index):
    """
    è¯„ä»·ç”¨æˆ·çš„æ“ä½œï¼Œç»“åˆåˆ†å‹ã€MACDå’ŒèƒŒé©°
    action: 'buy', 'sell', 'hold'
    current_index: å½“å‰Kçº¿åœ¨æ€»æ•°æ®ä¸­çš„ç´¢å¼•
    """
    # åŸºç¡€æ•°æ®å‡†å¤‡
    recent_k = klines[max(0, current_index-2):current_index+1]
    dif = macd_data['dif'][current_index]
    dea = macd_data['dea'][current_index]
    hist = macd_data['hist'][current_index]
    hist_prev = macd_data['hist'][current_index-1] if current_index > 0 else 0
    
    # å½¢æ€åˆ¤æ–­
    fenxing = identify_fenxing(recent_k)
    divergence_desc, divergence_shapes = check_divergence(klines, macd_data, current_index)
    
    # æ”¶é›†éœ€è¦é«˜äº®çš„åŒºåŸŸå½¢çŠ¶ (ä½¿ç”¨é‡æ„åçš„å‡½æ•°)
    highlight_shapes = get_chanlun_shapes(klines, macd_data, current_index)
    
    # å‡çº¿è¾…åŠ© (MA5, MA20)
    closes = [k['close'] for k in klines[:current_index+1]]
    ma5 = np.mean(closes[-5:]) if len(closes) >= 5 else closes[-1]
    ma20 = np.mean(closes[-20:]) if len(closes) >= 20 else closes[-1]
    trend = "å¤šå¤´" if ma5 > ma20 else "ç©ºå¤´"
    
    msg = []
    
    # 1. å¸‚åœºçŠ¶æ€æè¿°
    status_desc = []
    if hist > 0:
        if hist > hist_prev: status_desc.append("å¤šå¤´åŠ¨èƒ½å¢å¼º")
        else: status_desc.append("å¤šå¤´åŠ¨èƒ½è¡°å‡")
    else:
        if hist < hist_prev: status_desc.append("ç©ºå¤´åŠ¨èƒ½å¢å¼º")
        else: status_desc.append("ç©ºå¤´åŠ¨èƒ½è¡°å‡")
        
    if divergence_desc:
        status_desc.append(f"å‡ºç°{divergence_desc}")
    
    if fenxing == 'top': status_desc.append("å½¢æˆé¡¶åˆ†å‹")
    elif fenxing == 'bottom': status_desc.append("å½¢æˆåº•åˆ†å‹")
        
    msg.append(f"ğŸ§­ **å¸‚åœºçŠ¶æ€**: {', '.join(status_desc)} ({trend}æ’åˆ—)")

    # 2. æ“ä½œè¯„ä»·
    eval_msg = ""
    score = 0 # 1: åˆç†/æä½³, 0: æ™®é€š/ä¸­æ€§, -1: ä¸åˆç†/å¤±è¯¯
    
    if action == 'buy':
        if divergence_desc and "åº•èƒŒé©°" in divergence_desc:
            eval_msg = "ğŸ”¥ **æä½³æ“ä½œ (ä¸€ä¹°)**ï¼šèƒŒé©°å¼•å‘è½¬æŠ˜ï¼Œç²¾å‡†æ•æ‰ç¬¬ä¸€ç±»ä¹°ç‚¹ã€‚æ¬¡çº§åˆ«èµ°åŠ¿èƒŒé©°ç¡®ç«‹ï¼Œå½“ä¸‹ä¹°å…¥ç¬¦åˆåŒºé—´å¥—å®šä½ã€‚"
            score = 1
        elif fenxing == 'bottom' and trend == 'å¤šå¤´':
            eval_msg = "âœ… **é¡ºåŠ¿æ“ä½œ (äºŒä¹°/ä¸‰ä¹°)**ï¼šåœ¨ä¸Šæ¶¨ä¸­æ¢ä¸Šæ–¹/é™„è¿‘å‡ºç°åº•åˆ†å‹ï¼Œç¡®è®¤ä¸ºæ¬¡çº§åˆ«å›è°ƒç»“æŸï¼Œé¡ºåŠ¿ä»‹å…¥åäº«ä¸»å‡æµªã€‚"
            score = 1
        elif fenxing == 'bottom':
            eval_msg = "âš ï¸ **ä¸­ç»§é£é™© (ä¸‹è·Œä¸­ç»§)**ï¼šç©ºå¤´ä¸­æ¢å‹åˆ¶ä¸‹çš„åº•åˆ†å‹ï¼Œå¾€å¾€æ˜¯ä¸‹è·Œä¸­ç»§è€Œéåè½¬ï¼Œéœ€è­¦æƒ•å½¢æˆç¬¬ä¸‰ç±»å–ç‚¹ã€‚" # ä¿®æ­£ä¸ºæ›´ä¸“ä¸šçš„è¡¨è¿°
            score = 0
        elif hist > 0 and hist > hist_prev:
            eval_msg = "âš ï¸ **è¿½æ¶¨é£é™©**ï¼šçº¢æŸ±åŠ é€Ÿä¼¸é•¿æ—¶ä¹°å…¥ï¼Œæ­¤æ—¶å¾€å¾€å¤„äºå‘ä¸Šç¬”çš„æœ«ç«¯ï¼Œå®¹æ˜“åœ¨å°çº§åˆ«ä¹°åœ¨å±±é¡¶ã€‚"
            score = 0
        else:
            eval_msg = "âŒ **æ— æ•ˆæ“ä½œ**ï¼šå½“å‰æ— åº•åˆ†å‹ã€æ— èƒŒé©°ç»“æ„ï¼Œå±äºéšæ„å¼€ä»“ã€‚ç¼ è®ºå‘Šè¯«ï¼šæ²¡æœ‰ä¹°ç‚¹å°±æ²¡æœ‰æ“ä½œã€‚"
            score = -1
            
    elif action == 'sell':
        if divergence_desc and "é¡¶èƒŒé©°" in divergence_desc:
            eval_msg = "ğŸ”¥ **æä½³æ“ä½œ (ä¸€å–)**ï¼šé¡¶èƒŒé©°ä¿¡å·ç¡®è®¤ï¼Œå½“ä¸‹å³æ˜¯ç¬¬ä¸€ç±»å–ç‚¹ã€‚åŠ¨åŠ›å­¦è¡°ç«­å¼•å‘èµ°åŠ¿è½¬æŠ˜ï¼Œæœæ–­ç¦»åœºã€‚"
            score = 1
        elif fenxing == 'top' and trend == 'ç©ºå¤´':
            eval_msg = "âœ… **é¡ºåŠ¿å‡ä»“ (äºŒå–/ä¸‰å–)**ï¼šä¸‹è·Œè¶‹åŠ¿åå¼¹å—é˜»ï¼Œå‡ºç°é¡¶åˆ†å‹ï¼Œç¡®è®¤ä¸ºæ¬¡çº§åˆ«åå¼¹ç»“æŸï¼Œé¡ºåŠ¿ç¦»åœºé˜²å®ˆã€‚"
            score = 1
        elif fenxing == 'top':
            eval_msg = "âš ï¸ **çŸ­å·®æ“ä½œ**ï¼šå¤šå¤´è¶‹åŠ¿ä¸­å‡ºç°é¡¶åˆ†å‹ï¼Œå¤§æ¦‚ç‡æ˜¯ä¸Šæ¶¨ä¸­ç»§ï¼ˆæ„ç­‘æ–°çš„ä¸Šæ¶¨ä¸­æ¢ï¼‰ï¼Œä»…é€‚åˆçŸ­çº¿åšTã€‚"
            score = 0
        elif hist < 0 and hist < hist_prev:
            eval_msg = "âš ï¸ **æ€è·Œé£é™©**ï¼šç»¿æŸ±ä¼¸é•¿æ—¶å–å‡ºå¾€å¾€æ»åï¼Œå®¹æ˜“å–åœ¨å‘ä¸‹ç¬”çš„åº•ç«¯ã€‚åº”ç­‰å¾…åå¼¹æ„æˆäºŒå–/ä¸‰å–å†ç¦»åœºã€‚"
            score = 0
        else:
            eval_msg = "âŒ **æ— åºæ“ä½œ**ï¼šå½“å‰æ— é¡¶åˆ†å‹ã€æ— èƒŒé©°ç»“æ„ï¼Œå±äºææ…Œæ€§æŠ›å”®ã€‚ç¼ è®ºé“å¾‹ï¼šå–ç‚¹éƒ½åœ¨ä¸Šæ¶¨ä¸­äº§ç”Ÿã€‚"
            score = -1
            
    elif action == 'hold':
        if divergence_desc and "åº•èƒŒé©°" in divergence_desc:
            eval_msg = "âŒ **é”™å¤±ä¹°ç‚¹**ï¼šå½“ä¸‹å‡ºç°åº•èƒŒé©°ä¸€ä¹°ä¿¡å·ï¼æ ¹æ®â€œèµ°åŠ¿ç»ˆå®Œç¾â€ï¼Œæ­¤å¤„æå¤§æ¦‚ç‡å‘ç”Ÿè½¬æŠ˜ï¼Œè§‚æœ›å°†é”™å¤±è‰¯æœºã€‚"
            score = -1
        elif divergence_desc and "é¡¶èƒŒé©°" in divergence_desc:
            eval_msg = "âš ï¸ **é£é™©æç¤º**ï¼šå½“ä¸‹å‡ºç°é¡¶èƒŒé©°ä¸€å–ä¿¡å·ï¼åŠ¨åŠ›å­¦å·²è¡°ç«­ï¼Œæ­¤æ—¶ä¸èµ°ï¼Œæ›´å¾…ä½•æ—¶ï¼Ÿ"
            score = -1
        elif fenxing == 'bottom' and trend == 'å¤šå¤´':
            eval_msg = "â„¹ï¸ **å…³æ³¨æœºä¼š**ï¼šå¤šå¤´å›è°ƒç¡®è®¤åº•åˆ†å‹ï¼Œè¿™æ˜¯æ½œåœ¨çš„äºŒä¹°/ä¸‰ä¹°ä½ç½®ï¼Œå»ºè®®æ‹©æœºä»‹å…¥ã€‚"
            score = 0
        elif fenxing == 'top' and trend == 'ç©ºå¤´':
            eval_msg = "â„¹ï¸ **å…³æ³¨é£é™©**ï¼šç©ºå¤´åå¼¹ç¡®è®¤é¡¶åˆ†å‹ï¼Œè¿™æ˜¯æ½œåœ¨çš„äºŒå–/ä¸‰å–ä½ç½®ï¼ŒæŒä»“é£é™©å·¨å¤§ã€‚"
            score = 0
        else:
            eval_msg = "â˜• **ä¸­æ¢éœ‡è¡/é¡ºåŠ¿æŒæœ‰**ï¼šèµ°åŠ¿å»¶ç»­ä¸­ï¼ˆæ— é¡¶åº•èƒŒé©°ç ´åï¼‰ï¼Œç¬¦åˆâ€œä¸æ‚£â€åŸåˆ™ï¼Œè€å¿ƒæŒæœ‰æˆ–ç©ºä»“è§‚æœ›æ˜¯æœ€é«˜æ™ºæ…§ã€‚"
            score = 1

    msg.append(eval_msg)
    
    return "\n\n".join(msg), score, highlight_shapes

def _analyze_level_status(klines, macd_data, idx):
    """
    è¾…åŠ©å‡½æ•°ï¼šåˆ†æå•ä¸ªçº§åˆ«çš„è¶‹åŠ¿å’Œç»“æ„
    è¿”å›: stats å­—å…¸ (ä»¥å‰æ˜¯tuple)
    """
    if idx < 0 or idx >= len(klines):
        return None
        
    # 1. å‡çº¿è¶‹åŠ¿
    closes = [k['close'] for k in klines[:idx+1]]
    ma5 = np.mean(closes[-5:]) if len(closes) >= 5 else closes[-1]
    ma20 = np.mean(closes[-20:]) if len(closes) >= 20 else closes[-1]
    trend = 'UP' if ma5 > ma20 else 'DOWN'
    ma_desc = "å‡çº¿å¤šå¤´" if trend == 'UP' else "å‡çº¿ç©ºå¤´"
    
    signals = []
    
    # 2. åˆ†å‹
    range_k = klines[:idx+1] # ä¼ å…¥å…¨éƒ¨å†å²ä¾›åˆ‡ç‰‡
    fenxing = identify_fenxing(range_k) # identify_fenxing å†…éƒ¨ä¼šå–æœ€å3æ ¹
    if fenxing == 'top': signals.append('é¡¶åˆ†å‹')
    elif fenxing == 'bottom': signals.append('åº•åˆ†å‹')
    
    # 3. èƒŒé©° (åªçœ‹æœ€è¿‘çš„)
    try:
        div_desc, _ = check_divergence(klines, macd_data, idx)
        if div_desc:
            if 'é¡¶èƒŒé©°' in div_desc: signals.append('é¡¶èƒŒé©°')
            if 'åº•èƒŒé©°' in div_desc: signals.append('åº•èƒŒé©°')
    except Exception:
        pass

    # 4. MACD çŠ¶æ€
    macd_desc = "MACDæ•°æ®ç¼ºå¤±"
    try:
        # macd_data ç»“æ„æ˜¯ {'dif': [...], 'dea': [...], 'hist': [...]}
        # å¿…é¡»é€šè¿‡ key è®¿é—® list
        if idx < len(macd_data['hist']):
            hist = macd_data['hist'][idx]
            
            # è·å–å‰ä¸€æ ¹histç”¨äºæ¯”è¾ƒ
            prev_hist = macd_data['hist'][idx-1] if idx > 0 else hist
            
            if hist > 0:
                macd_desc = "çº¢æŸ±" + ("ä¼¸é•¿" if hist >= prev_hist else "ç¼©çŸ­")
            else:
                macd_desc = "ç»¿æŸ±" + ("ä¼¸é•¿" if hist <= prev_hist else "ç¼©çŸ­")
    except Exception:
        pass
        
    return {
        'trend': trend,
        'signals': signals,
        'ma_desc': ma_desc,
        'macd_desc': macd_desc
    }

def analyze_advanced_action(action, current_idx, day_data, day_macd, week_data, week_macd, month_data, month_macd):
    """
    é«˜çº§æ¨¡å¼åˆ†æï¼Œç»“åˆæ—¥ã€å‘¨ã€æœˆçº¿è¿›è¡Œè”åŠ¨åˆ†æ
    """
    # 1. åŸºç¡€æ—¥çº¿åˆ†æ (ä¿æŒåŸæœ‰çš„æ—¥çº¿è¯„ä»·é€»è¾‘)
    # day_msg æ ¼å¼é€šå¸¸ä¸º: "**å¸‚åœºçŠ¶æ€**: ... \n\n **è¯„ä»·**: ..."
    day_msg_text, day_score, day_shapes = analyze_action(action, day_data, day_macd, current_idx)
    
    # 2. å¯»æ‰¾å¯¹åº”çš„å‘¨ã€æœˆçº¿ç´¢å¼•
    c_time = day_data[current_idx]['time']
    
    week_idx = -1
    for i, w in enumerate(week_data):
        if w['start_day_idx'] <= c_time <= w['end_day_idx']:
            week_idx = i
            break
            
    month_idx = -1
    for i, m in enumerate(month_data):
        if m['start_day_idx'] <= c_time <= m['end_day_idx']:
            month_idx = i
            break
            
    if week_idx < 0:
        return day_msg_text + "\n\n(å¤§çº§åˆ«æ•°æ®ä¸è¶³)", day_score, day_shapes

    # 3. åˆ†æå¤§çº§åˆ«çŠ¶æ€
    w_stats = _analyze_level_status(week_data, week_macd, week_idx)
    m_stats = _analyze_level_status(month_data, month_macd, month_idx)
    
    if not w_stats or not m_stats:
        return day_msg_text + "\n\n(å¤§çº§åˆ«æ•°æ®ä¸è¶³)", day_score, day_shapes
        
    w_trend = w_stats['trend']
    w_signals = w_stats['signals']
    
    m_trend = m_stats['trend']
    m_signals = m_stats['signals']

    # 4. ç”Ÿæˆè”åŠ¨åˆ†æå’Œå…±æŒ¯è¯„ä»·
    linkage_msg = ""
    bonus_score = 0
    
    # æ ¹æ®æ“ä½œæ–¹å‘ + å¤§çº§åˆ«èƒŒæ™¯ç”Ÿæˆæ·±åº¦å»ºè®®
    if action == 'buy':
        if w_trend == 'UP':
            linkage_msg = "âœ… **å¤§çº§åˆ«é¡ºåŠ¿**ï¼šå‘¨çº¿å‘ä¸Šç¬”/çº¿æ®µå»¶ä¼¸ä¸­ï¼Œæ—¥çº¿ä¹°ç‚¹å±äºé¡ºå¤§åŠ¿æ“ä½œï¼ŒæˆåŠŸç‡æé«˜ã€‚"
            if 'åº•åˆ†å‹' in w_signals: linkage_msg += " (å‘¨çº¿åº•åˆ†å‹å…±æŒ¯ï¼Œæä½³)"
            bonus_score += 1
        elif w_trend == 'DOWN':
            if 'åº•èƒŒé©°' in w_signals:
                linkage_msg = "ğŸ”¥ **åŒºé—´å¥—å…±æŒ¯**ï¼šå‘¨çº¿åº•èƒŒé©°æ„ç­‘å¤§çº§åˆ«ä¸€ä¹°ï¼Œæ—¥çº¿ä½œä¸ºæ¬¡çº§åˆ«ç²¾ç¡®æ‰“å‡»ï¼Œè¿™æ˜¯ç¼ è®ºåŒºé—´å¥—çš„å®Œç¾åº”ç”¨ã€‚"
                bonus_score += 2
            elif 'åº•åˆ†å‹' in w_signals:
                linkage_msg = "âš ï¸ **å‘¨çº¿åå¼¹**ï¼šå‘¨çº¿ç©ºå¤´ç»“æ„ä¸­å‡ºç°åº•åˆ†å‹ï¼Œé¢„ç¤ºæ¬¡çº§åˆ«åå¼¹ï¼ˆæˆ–è®¸æ˜¯æ„å»ºå¤§çº§åˆ«ä¸­æ¢ï¼‰ï¼Œæ“ä½œéœ€è°¨æ…ï¼Œå¿«è¿›å¿«å‡ºã€‚"
            else:
                linkage_msg = "ğŸ›‘ **é€†åŠ¿æ¥é£åˆ€**ï¼šå‘¨çº¿å¤„äºç©ºå¤´ä¸‹è·Œè¥¿é£çƒˆä¸­ï¼ˆå‡çº¿ç©ºæ’ï¼‰ï¼Œä¸”æ— æ­¢è·Œä¿¡å·ã€‚æ­¤æ—¶æ—¥çº¿çš„æ‰€è°“ä¹°ç‚¹å¾€å¾€æ˜¯â€œåˆ€å£èˆ”è¡€â€ã€‚"
                bonus_score -= 2
                
    elif action == 'sell':
        if w_trend == 'DOWN':
            linkage_msg = "âœ… **é¡ºåŠ¿ç¦»åœº**ï¼šå‘¨çº¿ç©ºå¤´å‘ä¸‹ï¼Œæ—¥çº¿å–å‡ºé¡ºåº”å¤§åŠ¿ï¼Œå»ºè®®ä¿æŒç©ºä»“ï¼Œç­‰å¾…å‘¨çº¿çº§åˆ«çš„åº•èƒŒé©°æˆ–åº•åˆ†å‹ã€‚"
            bonus_score += 1
        elif w_trend == 'UP':
            if 'é¡¶èƒŒé©°' in w_signals:
                linkage_msg = "ğŸ”¥ **é€ƒé¡¶è‰¯æœº**ï¼šå‘¨çº¿å¤šå¤´å‡ºç°é¡¶èƒŒé©°ï¼è¿™æ˜¯å¤§çº§åˆ«çš„å–å‡ºä¿¡å·ï¼ˆå¤§çº§åˆ«ä¸€å–ï¼‰ï¼Œæ—¥çº¿å–ç‚¹ä¸ä¹‹å…±æŒ¯ï¼ŒåŠ¡å¿…æ¸…ä»“ã€‚"
                bonus_score += 2
            elif 'é¡¶åˆ†å‹' in w_signals:
                linkage_msg = "âš ï¸ **å‘¨çº¿éœ‡è¡**ï¼šå‘¨çº¿å¤šå¤´ä¸­å‡ºç°é¡¶åˆ†å‹ï¼Œå¤§æ¦‚ç‡æ˜¯ä¸Šæ¶¨ä¸­æ¢çš„éœ‡è¡æ´—ç›˜ã€‚å–å‡ºåéœ€å…³æ³¨å›è°ƒç»“æŸåçš„ä¸‰ä¹°æœºä¼šã€‚"
            else:
                linkage_msg = "ğŸ›‘ **é€†åŠ¿å–å‡º**ï¼šå‘¨çº¿å¤šå¤´å¼ºåŠ²ï¼ˆå‡çº¿å¤šæ’ï¼‰ï¼Œæ—¥çº¿è°ƒæ•´å¯èƒ½ä»…æ˜¯æ„ç­‘æ¬¡çº§åˆ«ä¸­æ¢ï¼Œç›²ç›®å–å‡ºå®¹æ˜“â€œå–é£â€ä¸»å‡æµªã€‚"
                bonus_score -= 1 # æ‰£åˆ†ï¼Œå› ä¸ºå®¹æ˜“å–é£

    elif action == 'hold':
        if w_trend == 'UP':
             if 'é¡¶èƒŒé©°' in w_signals:
                 linkage_msg = "âš ï¸ **è­¦æƒ•è§é¡¶**ï¼šè™½ç„¶æ—¥çº¿å¹³ç¨³ï¼Œä½†å‘¨çº¿å·²å‡ºç°é¡¶èƒŒé©°ï¼Œå¤§å¦å°†å€¾ï¼ŒæŒä»“éœ€é«˜åº¦è­¦æƒ•ï¼Œéšæ—¶å‡†å¤‡ç¦»åœºã€‚"
             else:
                 linkage_msg = "â˜• **ä¸­æ¢ä¸Šç§»**ï¼šå‘¨çº¿å¤šå¤´è¶‹åŠ¿å¥åº·ï¼Œæ¬¡çº§åˆ«çš„éœ‡è¡åªæ˜¯ä¸­æ¢ä¸Šç§»çš„è¿‡ç¨‹ï¼ŒæŒä»“èººèµ¢æ˜¯æœ€ä½³ç­–ç•¥ã€‚"
        elif w_trend == 'DOWN':
             if 'åº•èƒŒé©°' in w_signals:
                 linkage_msg = "â„¹ï¸ **æŠ„åº•å‡†å¤‡**ï¼šå‘¨çº¿å‡ºç°åº•èƒŒé©°ï¼Œå¤§åº•å°†è¿‘ï¼Œç©ºä»“è€…åº”å¯†åˆ‡å…³æ³¨æ—¥çº¿ä¸€ä¹°/äºŒä¹°ï¼Œå‡†å¤‡è¿›åœºã€‚"
             else:
                 linkage_msg = "â˜• **ç©ºä»“ä¸ºç‹**ï¼šå‘¨çº¿ç©ºå¤´è¶‹åŠ¿å»¶ç»­ä¸­ï¼Œè¦†å·¢ä¹‹ä¸‹æ— å®Œåµï¼Œè€å¿ƒè§‚æœ›ç­‰å¾…å¤§çº§åˆ«ä¹°ç‚¹ã€‚"

    # 5. ç»„åˆæœ€ç»ˆæ–‡æ¡ˆ
    final_output = []
    
    # å¦‚æœæœ‰è”åŠ¨è¯„ä»·ï¼Œä¼˜å…ˆæ˜¾ç¤º
    if linkage_msg:
        final_output.append(linkage_msg)
    else:
        # å¦åˆ™ä½¿ç”¨æ—¥çº¿åŸºç¡€è¯„ä»·
        pass
        
    final_output.append(day_msg_text)
    
    # çŠ¶æ€æ‘˜è¦ - å¢å¼ºç‰ˆ
    def fmt_level(name, stats):
        sig_str = ', '.join(stats['signals']) if stats['signals'] else 'æ— ç»“æ„'
        return f"â€¢ **{name}**: {stats['ma_desc']} | {stats['macd_desc']} | {sig_str}"
        
    status_summary = (
        f"ğŸ“Š **å¤§çº§åˆ«å…¨æ™¯**\n"
        f"{fmt_level('å‘¨çº¿', w_stats)}\n"
        f"{fmt_level('æœˆçº¿', m_stats)}"
    )
    final_output.append(status_summary)
    
    # è°ƒæ•´åˆ†æ•°
    final_score = day_score
    if bonus_score > 0 and day_score >= 0: final_score = 1
    if bonus_score < 0 and day_score >= 0: final_score = 0 # é™çº§
    if bonus_score <= -2: final_score = -1 # ä¸¥é‡æ‰£åˆ†
    
    return "\n\n".join(final_output), final_score, day_shapes
