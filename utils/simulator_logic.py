import numpy as np
import random

def calculate_ema(values, span):
    values = np.array(values, dtype=float)
    if len(values) == 0:
        return np.array([])
    alpha = 2 / (span + 1)
    ema = np.zeros_like(values)
    ema[0] = values[0]
    for i in range(1, len(values)):
        ema[i] = alpha * values[i] + (1 - alpha) * ema[i-1]
    return ema

def calculate_macd(close_prices, fast_period=12, slow_period=26, signal_period=9):
    values = np.array(close_prices, dtype=float)
    if len(values) == 0:
        return {'dif': [], 'dea': [], 'hist': []}
        
    ema_fast = calculate_ema(values, fast_period)
    ema_slow = calculate_ema(values, slow_period)
    
    dif = ema_fast - ema_slow
    dea = calculate_ema(dif, signal_period)
    hist = (dif - dea) * 2
    
    return {
        'dif': dif.tolist(),
        'dea': dea.tolist(),
        'hist': hist.tolist()
    }

def generate_simulation_data(initial_price=100, length=300):
    """
    ç”Ÿæˆæ¨¡æ‹Ÿçš„Kçº¿æ•°æ®
    """
    data = []
    # ç¡®ä¿åˆå§‹ä»·æ ¼åœ¨åˆç†èŒƒå›´å†… (1~1000)
    initial_price = max(5.0, min(950.0, float(initial_price)))
    price = initial_price
    trend = 0  # è¶‹åŠ¿å› å­ (ç™¾åˆ†æ¯”)
    
    for i in range(length):
        # 1. ç¡®å®šä»Šæ—¥æ¶¨è·Œåœé™åˆ¶ (æ˜¨æ”¶ * 1.1 / 0.9)
        # æ¶¨è·Œå¹…æœ€å¤§ 10%
        limit_up = round(price * 1.10, 2)
        limit_down = round(price * 0.90, 2)
        
        # 2. åªæœ‰åœ¨ä»·æ ¼èŒƒå›´å†… (1~1000) æ‰æœ‰æ•ˆ
        limit_up = min(limit_up, 1000.0)
        limit_down = max(limit_down, 1.0)
        
        # å¶å°”æ”¹å˜è¶‹åŠ¿ (æ¯30å¤©)
        if i % 30 == 0: 
            # è¶‹åŠ¿åç½®: æ¯å¤©å€¾å‘æ¶¨/è·Œå¤šå°‘ç™¾åˆ†æ¯” (-1% åˆ° 1%)
            trend = np.random.normal(0, 0.005) 
            
        # 3. ç”Ÿæˆå¼€ç›˜ä»· (Pre-market fluctuation)
        # å¤šæ•°æ—¶å€™å¹³å¼€ï¼Œå¶å°”å°å¹…é«˜å¼€ä½å¼€
        open_shock = np.random.normal(0, 0.005) 
        open_p = price * (1 + open_shock)
        
        # 4. ç”Ÿæˆæ”¶ç›˜ä»· (Day fluctuation based on trend)
        # æ—¥å†…æ³¢åŠ¨ ~2% + è¶‹åŠ¿
        day_change = np.random.normal(0, 0.02) + trend
        close_p = price * (1 + day_change)
        
        # 5. ç”Ÿæˆæœ€é«˜æœ€ä½ (High/Low)
        # åŸºäºopen/close æ‰©å±•
        raw_high = max(open_p, close_p) * (1 + abs(np.random.normal(0, 0.01)))
        raw_low = min(open_p, close_p) * (1 - abs(np.random.normal(0, 0.01)))
        
        # 6. ä¿®æ­£æ‰€æœ‰ä»·æ ¼åˆ°é™åˆ¶èŒƒå›´å†…
        def clamp(val):
            return max(limit_down, min(limit_up, val))
            
        open_p = clamp(open_p)
        close_p = clamp(close_p)
        high_p = clamp(raw_high)
        low_p = clamp(raw_low)
        
        # 7. å†æ¬¡ç¡®ä¿é€»è¾‘ä¸€è‡´æ€§ (H >= max(O,C), L <= min(O,C))
        high_p = max(high_p, open_p, close_p)
        low_p = min(low_p, open_p, close_p)

        data.append({
            'time': i,
            'open': round(open_p, 2),
            'high': round(high_p, 2),
            'low': round(low_p, 2),
            'close': round(close_p, 2)
        })
        
        price = close_p

    # è®¡ç®—MACD
    closes = [d['close'] for d in data]
    macd = calculate_macd(closes)
    
    return data, macd

def identify_fenxing(klines):
    """
    ç®€å•åˆ¤æ–­æœ€å3æ ¹Kçº¿æ˜¯å¦æ„æˆé¡¶åˆ†å‹æˆ–åº•åˆ†å‹
    klines: è‡³å°‘åŒ…å«æœ€å3æ ¹Kçº¿çš„æ•°æ® list of dict
    """
    if len(klines) < 3:
        return None
        
    k1, k2, k3 = klines[-3], klines[-2], klines[-1]
    
    # ç®€å•çš„é¡¶åˆ†å‹å®šä¹‰ï¼šä¸­é—´Kçº¿é«˜ç‚¹æœ€é«˜ï¼Œåº•ä¸æœ€ä½ï¼ˆè¿™é‡Œç®€åŒ–ï¼Œä¸¥è°¨ç¼ è®ºéœ€è¦åŒ…å«å¤„ç†ï¼‰
    # ç¼ è®ºæ ‡å‡†ï¼šé¡¶åˆ†å‹æ˜¯ä¸­æŒ‡æœ€é«˜ç‚¹æœ€é«˜ï¼Œæœ€ä½ç‚¹ä¹Ÿæœ€é«˜ï¼ˆä¸åŒ…å«å…³ç³»åï¼‰
    # è¿™é‡Œæˆ‘ä»¬å‡è®¾å·²ç»ç»è¿‡åŒ…å«å¤„ç†ï¼Œæˆ–è€…ç®€å•åˆ¤æ–­é«˜ä½ç‚¹
    
    is_top = k2['high'] > k1['high'] and k2['high'] > k3['high']
    is_bottom = k2['low'] < k1['low'] and k2['low'] < k3['low']
    
    if is_top: return 'top'
    if is_bottom: return 'bottom'
    return None

def check_divergence(klines, macd_data, index, lookback=30):
    """
    æ£€æŸ¥èƒŒé©°ï¼Œè¿”å›æè¿°å’Œéœ€è¦é«˜äº®çš„å½¢çŠ¶æ•°æ®
    """
    if index < lookback: return None, []
    
    current_k = klines[index]
    current_hist = macd_data['hist'][index]
    
    # ä»¥å‰ lookback æ ¹Kçº¿ä½œä¸ºå‚è€ƒç³»
    start_lookback = index - lookback
    prev_klines = klines[start_lookback:index]
    prev_hists = macd_data['hist'][start_lookback:index]
    
    if not prev_klines: return None, []

    # ---åº•èƒŒé©°åˆ¤æ–­---
    # æ¡ä»¶1ï¼šåˆ›æ–°ä½
    min_prev_low = float('inf')
    min_prev_idx = -1
    
    for i, k in enumerate(prev_klines):
        if k['low'] < min_prev_low:
            min_prev_low = k['low']
            # i æ˜¯ç›¸å¯¹ prev_klines çš„ç´¢å¼•ï¼Œmin_prev_idx éœ€è¦æ˜¯å…¨å±€ç´¢å¼•
            min_prev_idx = start_lookback + i
            
    if current_k['low'] < min_prev_low:
        # æ¡ä»¶2ï¼šMACDç»¿æŸ±æ²¡æœ‰åˆ›æ–°ä½ (åŠ¨èƒ½è¡°ç«­)
        min_hist_prev = min(prev_hists)
        
        # æ‰¾åˆ°å‰ä½MACDçš„ç´¢å¼•ï¼Œç”¨äºç”»å›¾
        min_hist_idx_rel = prev_hists.index(min_hist_prev)
        min_hist_idx = start_lookback + min_hist_idx_rel
        
        if current_hist < 0 and current_hist > min_hist_prev:
            shapes = [
                # 1. Kçº¿å›¾ï¼šèƒŒé©°è¿çº¿ (åŠ ç²—å®çº¿)
                {
                    'type': 'line',
                    'xref': 'x', 'yref': 'y',
                    'x0': min_prev_idx, 'y0': min_prev_low,
                    'x1': index, 'y1': current_k['low'],
                    'line': {'color': 'rgb(128, 128, 128)', 'width': 3} # ç°è‰²
                },
                # 2. Kçº¿å›¾ï¼šèƒŒé©°åŒºé—´èƒŒæ™¯ (æ·¡çº¢é«˜äº®)
                {
                    'type': 'rect',
                    'xref': 'x', 'yref': 'y',
                    'x0': min_prev_idx,
                    'x1': index,
                    'y0': min(min_prev_low, current_k['low']) * 0.99, # ç¨å¾®æ‰©ä¸€ç‚¹èŒƒå›´
                    'y1': max(min_prev_low, current_k['low']) * 1.01,
                    'fillcolor': 'rgba(254, 202, 202, 0.4)', # Red-200
                    'line': {'width': 0}
                },
                # 3. MACDå›¾ï¼šèƒŒé©°è¿çº¿ (è™šçº¿æŒ‡ç¤º)
                {
                    'type': 'line',
                    'xref': 'x', 'yref': 'y2', # æŒ‡å‘å‰¯å›¾Yè½´
                    'x0': min_hist_idx, 'y0': min_hist_prev,
                    'x1': index, 'y1': current_hist,
                    'line': {'color': 'rgb(128, 128, 128)', 'width': 2, 'dash': 'dot'} 
                }
            ]
            return "åº•èƒŒé©°ï¼ˆä»·æ ¼æ–°ä½ä½†ç»¿æŸ±æœªåŠ æ·±ï¼‰", shapes
            
    # ---é¡¶èƒŒé©°åˆ¤æ–­---
    # æ¡ä»¶1ï¼šåˆ›æ–°é«˜
    max_prev_high = float('-inf')
    max_prev_idx = -1
    
    for i, k in enumerate(prev_klines):
        if k['high'] > max_prev_high:
            max_prev_high = k['high']
            max_prev_idx = start_lookback + i
            
    if current_k['high'] > max_prev_high:
        # æ¡ä»¶2ï¼šMACDçº¢æŸ±æ²¡æœ‰åˆ›æ–°é«˜
        max_hist_prev = max(prev_hists)
        
        # æ‰¾åˆ°å‰é«˜MACDçš„ç´¢å¼•
        max_hist_idx_rel = prev_hists.index(max_hist_prev)
        max_hist_idx = start_lookback + max_hist_idx_rel
        
        if current_hist > 0 and current_hist < max_hist_prev:
            shapes = [
                # 1. Kçº¿å›¾ï¼šèƒŒé©°è¿çº¿ (åŠ ç²—å®çº¿)
                {
                    'type': 'line',
                    'xref': 'x', 'yref': 'y',
                    'x0': max_prev_idx, 'y0': max_prev_high,
                    'x1': index, 'y1': current_k['high'],
                    'line': {'color': 'rgb(128, 128, 128)', 'width': 3} # ç°è‰²
                },
                # 2. Kçº¿å›¾ï¼šèƒŒé©°åŒºé—´èƒŒæ™¯ (æ·¡ç»¿é«˜äº®)
                {
                    'type': 'rect',
                    'xref': 'x', 'yref': 'y',
                    'x0': max_prev_idx,
                    'x1': index,
                    'y0': min(max_prev_high, current_k['high']) * 0.99,
                    'y1': max(max_prev_high, current_k['high']) * 1.01,
                    'fillcolor': 'rgba(187, 247, 208, 0.4)', # Green-200
                    'line': {'width': 0}
                },
                # 3. MACDå›¾ï¼šèƒŒé©°è¿çº¿ (è™šçº¿æŒ‡ç¤º)
                {
                    'type': 'line',
                    'xref': 'x', 'yref': 'y2', # æŒ‡å‘å‰¯å›¾Yè½´
                    'x0': max_hist_idx, 'y0': max_hist_prev,
                    'x1': index, 'y1': current_hist,
                    'line': {'color': 'rgb(128, 128, 128)', 'width': 2, 'dash': 'dot'}
                }
            ]
            return "é¡¶èƒŒé©°ï¼ˆä»·æ ¼æ–°é«˜ä½†çº¢æŸ±æœªå¢é•¿ï¼‰", shapes
            
    return None, []

def resample_klines(daily_data, period):
    """
    å°†æ—¥çº¿æ•°æ®é‡é‡‡æ ·ä¸ºæ›´å¤§çº§åˆ«çš„æ•°æ® (å‘¨K, æœˆKç­‰)
    period: èšåˆçš„Kçº¿æ•°é‡ï¼Œä¾‹å¦‚ 5 (å‘¨), 20 (æœˆ), 60 (å­£)
    """
    resampled = []
    if not daily_data:
        return [], calculate_macd([]) # è¿”å›ç©ºMACDç»“æ„

    # æŒ‰å›ºå®šå‘¨æœŸåˆ†å—
    for i in range(0, len(daily_data), period):
        chunk = daily_data[i : i + period]
        if not chunk: continue
        
        # èšåˆ
        open_p = chunk[0]['open']
        close_p = chunk[-1]['close']
        high_p = max(d['high'] for d in chunk)
        low_p = min(d['low'] for d in chunk)
        
        # ä½¿ç”¨æ–°çš„ç´¢å¼•ä½œä¸ºtime
        new_time = len(resampled)
        
        resampled.append({
            'time': new_time,
            'open': open_p,
            'high': high_p,
            'low': low_p,
            'close': close_p,
            # ä¿ç•™åŸå§‹çš„å¯¹åº”æ—¥çº¿ç´¢å¼•èŒƒå›´ï¼Œç”¨äºUIæ˜ å°„
            'start_day_idx': chunk[0]['time'],
            'end_day_idx': chunk[-1]['time']
        })
        
    # è®¡ç®—æ–°çº§åˆ«çš„MACD
    closes = [d['close'] for d in resampled]
    macd = calculate_macd(closes)
    
    return resampled, macd

def calculate_bi_and_zhongshu_shapes(klines):
    """
    è®¡ç®—å¹¶è¿”å›ç¬”ï¼ˆBiï¼‰å’Œä¸­æ¢ï¼ˆZhongshu/Boxï¼‰çš„å½¢çŠ¶æ•°æ®
    ç®€åŒ–ç‰ˆé€»è¾‘ï¼Œä»…ç”¨äºæ¨¡æ‹Ÿå™¨å±•ç¤ºè¾…åŠ©
    """
    shapes = []
    
    # 1. è¯†åˆ«æ‰€æœ‰åˆ†å‹ç‚¹ (Fenxing Points)
    fenxings = [] # list of {'index': i, 'type': 'top'/'bottom', 'val': price}
    
    # è¿™é‡Œéœ€è¦éå†æ•´ä¸ªåºåˆ—æ¥é€šè¿‡äº¤æ›¿è§„åˆ™ç¡®è®¤ç¬”
    # æ³¨æ„ï¼šklines æ˜¯æˆªæ­¢åˆ°å½“å‰çš„å…¨éƒ¨æ•°æ®ï¼Œæˆ‘ä»¬é‡æ–°è®¡ç®—æ•´ä¸ªå†å²çš„ç¬”
    for i in range(2, len(klines)):
        subset = klines[i-2 : i+1]
        fx_type = identify_fenxing(subset)
        if fx_type:
            # ç®€åŒ–ç‰ˆç¬”è¯†åˆ«é€»è¾‘ï¼š
            # 1. å¿…é¡»æ˜¯ä¸€é¡¶ä¸€åº•äº¤æ›¿
            # 2. é¡¶åº•ä¹‹é—´è‡³å°‘é—´éš”ä¸€å®šKçº¿ (è¿™é‡Œè®¾ä¸º3æ ¹ï¼Œå³ä¸­é—´æœ‰Kçº¿)
            k2 = subset[1]
            # k2çš„ç´¢å¼•åœ¨å…¨å±€åºåˆ—ä¸­æ˜¯ i-1
            k2_idx = i - 1
            val = k2['high'] if fx_type == 'top' else k2['low']
            
            if not fenxings:
                # ç¬¬ä¸€ä¸ªåˆ†å‹ç›´æ¥æ¥çº³
                fenxings.append({'index': k2_idx, 'type': fx_type, 'val': val})
            else:
                last = fenxings[-1]
                if last['type'] != fx_type:
                    # ç±»å‹ä¸åŒï¼Œæ£€æŸ¥è·ç¦»
                    if k2_idx - last['index'] >= 3:
                        fenxings.append({'index': k2_idx, 'type': fx_type, 'val': val})
                    # å¦‚æœè·ç¦»å¤ªè¿‘ï¼Œå¿½ç•¥è¿™ä¸ªæ–°åˆ†å‹ï¼ˆæˆ–è€…è¿™æ˜¯ä¸€ä¸ªæ›´ä¼˜çš„åˆ†å‹ï¼Ÿï¼‰
                    # ç®€åŒ–å¤„ç†ï¼šå¿½ç•¥è¿‡è¿‘çš„è½¬æŠ˜
                else:
                    # ç±»å‹ç›¸åŒï¼Œä¿ç•™æ›´æç«¯çš„é‚£ä¸ª
                    if fx_type == 'top':
                        if val > last['val']:
                            fenxings[-1] = {'index': k2_idx, 'type': fx_type, 'val': val}
                    else:
                        if val < last['val']:
                            fenxings[-1] = {'index': k2_idx, 'type': fx_type, 'val': val}

    # 2. ç”Ÿæˆç¬”çš„è¿çº¿ (Bi Shapes)
    bi_segments = [] 
    for i in range(len(fenxings) - 1):
        p1 = fenxings[i]
        p2 = fenxings[i+1]
        
        shapes.append({
            'type': 'line',
            'xref': 'x', 'yref': 'y',
            'x0': p1['index'], 'y0': p1['val'],
            'x1': p2['index'], 'y1': p2['val'],
            'line': {'color': 'rgba(70, 70, 70, 0.6)', 'width': 2}, # æ·±ç°è‰²å®çº¿
            # 'layer': 'below' # Plotly shape layer (not supported directly in dict always, simplified)
        })
        bi_segments.append({
            'x0': p1['index'], 'y0': p1['val'],
            'x1': p2['index'], 'y1': p2['val']
        })

    # 3. ç”Ÿæˆä¸­æ¢çŸ©å½¢ (Zhongshu Shapes)
    # é€»è¾‘ï¼šè¿ç»­ä¸‰ç¬”é‡å éƒ¨åˆ† -> å‡çº§é€»è¾‘ï¼šåˆå¹¶é‡å /è¿ç»­çš„ä¸­æ¢ä¸ºå¤§çº§åˆ«ä¸­æ¢
    raw_zhongshus = []
    if len(bi_segments) >= 3:
        for i in range(len(bi_segments) - 2):
            b1 = bi_segments[i]
            b2 = bi_segments[i+1]
            b3 = bi_segments[i+2]
            
            # è®¡ç®—ä¸‰ç¬”ä»·æ ¼åŒºé—´çš„äº¤é›† (ä¸­æ¢æ ¸å¿ƒåŒºåŸŸ)
            r1 = (min(b1['y0'], b1['y1']), max(b1['y0'], b1['y1']))
            r2 = (min(b2['y0'], b2['y1']), max(b2['y0'], b2['y1']))
            r3 = (min(b3['y0'], b3['y1']), max(b3['y0'], b3['y1']))
            
            overlap_min = max(r1[0], r2[0], r3[0])
            overlap_max = min(r1[1], r2[1], r3[1])
            
            if overlap_min < overlap_max:
                # å­˜åœ¨æœ‰æ•ˆä¸­æ¢åŒºåŸŸ
                raw_zhongshus.append({
                    'x0': b1['x0'], 
                    'x1': b3['x1'],
                    'y0': overlap_min,
                    'y1': overlap_max
                })

    # åˆå¹¶é‡å çš„ä¸­æ¢ (Expansion/Extension)
    merged_zhongshus = []
    if raw_zhongshus:
        # æŒ‰å¼€å§‹æ—¶é—´æ’åº (é€šå¸¸å·²ç»æ˜¯é¡ºåºçš„)
        current_z = raw_zhongshus[0]
        
        for i in range(1, len(raw_zhongshus)):
            next_z = raw_zhongshus[i]
            
            # åˆ¤æ–­æ˜¯å¦é‡å  (Overlap)
            # 1. æ—¶é—´ä¸Šï¼šraw_zhongshus æ˜¯åŸºäºæ»‘åŠ¨çª—å£ç”Ÿæˆçš„ï¼Œå¤©ç”Ÿæ—¶é—´é‡å /è¿ç»­
            # 2. ç©ºé—´ä¸Šï¼šåˆ¤æ–­ä»·æ ¼åŒºé—´æ˜¯å¦æœ‰äº¤é›†
            mn = max(current_z['y0'], next_z['y0'])
            mx = min(current_z['y1'], next_z['y1'])
            
            if mn < mx:
                # å­˜åœ¨ä»·æ ¼äº¤é›†ï¼Œè§†ä¸ºåŒä¸€ä¸­æ¢çš„å»¶ä¼¸/æ‰©å¼  -> åˆå¹¶
                # æ–°çš„èŒƒå›´ï¼šæ—¶é—´å¹¶é›†ï¼Œä»·æ ¼å¹¶é›† (ä½“ç°å¤§çº§åˆ«/æ‰©å¼ èŒƒå›´)
                # æ³¨ï¼šç¼ è®ºä¸¥æ ¼å®šä¹‰ä¸­æ¢çº§åˆ«å‡çº§éœ€è¦9æ®µï¼Œæˆ–è€…ä¸¤ä¸ªç‹¬ç«‹ä¸­æ¢æ³¢åŠ¨åŒºé—´é‡å ã€‚
                # è¿™é‡Œåšè§†è§‰ç®€åŒ–ï¼šå‡¡æ˜¯è¿åœ¨ä¸€èµ·ä¸”ä»·æ ¼é‡å çš„ï¼Œéƒ½ç”»æˆä¸€ä¸ªå¤§æ¡†ã€‚
                current_z['x1'] = max(current_z['x1'], next_z['x1'])
                current_z['y0'] = min(current_z['y0'], next_z['y0'])
                current_z['y1'] = max(current_z['y1'], next_z['y1'])
            else:
                # ä¸é‡å ï¼Œç»“æŸå½“å‰ä¸­æ¢ï¼Œå¼€å§‹ä¸‹ä¸€ä¸ª
                merged_zhongshus.append(current_z)
                current_z = next_z
        
        merged_zhongshus.append(current_z)

    # ç”Ÿæˆæœ€ç»ˆå½¢çŠ¶
    for z in merged_zhongshus:
        shapes.append({
            'type': 'rect',
            'xref': 'x', 'yref': 'y',
            'x0': z['x0'], 
            'x1': z['x1'],
            'y0': z['y0'],
            'y1': z['y1'],
            'fillcolor': 'rgba(255, 165, 0, 0.15)', # æ©™è‰²åŠé€æ˜
            'line': {'width': 0},
        })
        # ç”»è¾¹æ¡†
        shapes.append({
             'type': 'rect',
             'xref': 'x', 'yref': 'y',
             'x0': z['x0'], 
             'x1': z['x1'],
             'y0': z['y0'],
             'y1': z['y1'],
             'line': {'color': 'rgba(255, 165, 0, 0.6)', 'width': 1.5, 'dash': 'dot'}, # åŠ ç²—ä¸€ç‚¹è¾¹æ¡†
             'fillcolor': 'rgba(0,0,0,0)'
        })

    return shapes

def get_chanlun_shapes(klines, macd_data, current_index):
    """
    è®¡ç®—å¹¶è¿”å›Kçº¿å¯¹åº”çš„ç¬”ã€ä¸­æ¢ã€åˆ†å‹å’ŒèƒŒé©°å½¢çŠ¶
    åŠŸèƒ½é›†æˆï¼Œç”¨äºä»»æ„çº§åˆ«çš„Kçº¿åˆ†æ
    """
    highlight_shapes = []
    
    # 1. ç¬”å’Œä¸­æ¢
    # ä¸ºäº†æ€§èƒ½ï¼Œå¯ä»¥åªè®¡ç®—æœ€è¿‘çš„ä¸€æ®µï¼Œä½†ä¸ºäº†å‡†ç¡®æ€§ï¼Œè¿™é‡Œä¼ å…¥å…¨éƒ¨å†å²ï¼ˆklinesæ˜¯åˆ‡ç‰‡è¿‡çš„ï¼‰
    # åœ¨æ¨¡æ‹Ÿå™¨ä¸­ current_index < 400 å·¦å³ï¼Œè®¡ç®—å¼€é”€å¯æ§
    bi_zhongshu_shapes = calculate_bi_and_zhongshu_shapes(klines)
    highlight_shapes.extend(bi_zhongshu_shapes)
    
    # 2. èƒŒé©°
    divergence_desc, divergence_shapes = check_divergence(klines, macd_data, current_index)
    if divergence_shapes:
        highlight_shapes.extend(divergence_shapes)
    
    # 3. åˆ†å‹ï¼ˆå½“å‰Kçº¿ï¼‰
    recent_k = klines[max(0, current_index-2):current_index+1]
    fenxing = identify_fenxing(recent_k)
    
    if fenxing:
        k_subset = klines[current_index-2 : current_index+1]
        if k_subset:
            max_h = max(k['high'] for k in k_subset)
            min_l = min(k['low'] for k in k_subset)
            
            if fenxing == 'bottom':
                box_color = 'rgba(255, 0, 0, 0.1)' # åçº¢
                border_color = 'rgba(255, 0, 0, 0.5)'
            else:
                box_color = 'rgba(0, 128, 0, 0.1)' # åç»¿
                border_color = 'rgba(0, 128, 0, 0.5)'
            
            highlight_shapes.append({
                'type': 'rect',
                'xref': 'x', 'yref': 'y',
                'x0': current_index - 2 - 0.4, 
                'x1': current_index + 0.4,
                'y0': min_l,
                'y1': max_h,
                'fillcolor': box_color,
                'line': {'color': border_color, 'width': 1, 'dash': 'solid'}
            })
            
    return highlight_shapes

def analyze_action(action, klines, macd_data, current_index):
    """
    è¯„ä»·ç”¨æˆ·çš„æ“ä½œï¼Œç»“åˆåˆ†å‹ã€MACDå’ŒèƒŒé©°
    action: 'buy', 'sell', 'hold'
    current_index: å½“å‰Kçº¿åœ¨æ€»æ•°æ®ä¸­çš„ç´¢å¼•
    """
    # åŸºç¡€æ•°æ®å‡†å¤‡
    recent_k = klines[max(0, current_index-2):current_index+1]
    dif = macd_data['dif'][current_index]
    dea = macd_data['dea'][current_index]
    hist = macd_data['hist'][current_index]
    hist_prev = macd_data['hist'][current_index-1] if current_index > 0 else 0
    
    # å½¢æ€åˆ¤æ–­
    fenxing = identify_fenxing(recent_k)
    divergence_desc, divergence_shapes = check_divergence(klines, macd_data, current_index)
    
    # æ”¶é›†éœ€è¦é«˜äº®çš„åŒºåŸŸå½¢çŠ¶ (ä½¿ç”¨é‡æ„åçš„å‡½æ•°)
    highlight_shapes = get_chanlun_shapes(klines, macd_data, current_index)
    
    # å‡çº¿è¾…åŠ© (MA5, MA20)
    closes = [k['close'] for k in klines[:current_index+1]]
    ma5 = np.mean(closes[-5:]) if len(closes) >= 5 else closes[-1]
    ma20 = np.mean(closes[-20:]) if len(closes) >= 20 else closes[-1]
    trend = "å¤šå¤´" if ma5 > ma20 else "ç©ºå¤´"
    
    msg = []
    
    # 1. å¸‚åœºçŠ¶æ€æè¿°
    status_desc = []
    if hist > 0:
        if hist > hist_prev: status_desc.append("å¤šå¤´åŠ¨èƒ½å¢å¼º")
        else: status_desc.append("å¤šå¤´åŠ¨èƒ½è¡°å‡")
    else:
        if hist < hist_prev: status_desc.append("ç©ºå¤´åŠ¨èƒ½å¢å¼º")
        else: status_desc.append("ç©ºå¤´åŠ¨èƒ½è¡°å‡")
        
    if divergence_desc:
        status_desc.append(f"å‡ºç°{divergence_desc}")
    
    if fenxing == 'top': status_desc.append("å½¢æˆé¡¶åˆ†å‹")
    elif fenxing == 'bottom': status_desc.append("å½¢æˆåº•åˆ†å‹")
        
    msg.append(f"**å¸‚åœºçŠ¶æ€**: {', '.join(status_desc)} ({trend}æ’åˆ—)")

    # 2. æ“ä½œè¯„ä»·
    eval_msg = ""
    score = 0 # 1: åˆç†/æä½³, 0: æ™®é€š/ä¸­æ€§, -1: ä¸åˆç†/å¤±è¯¯
    
    if action == 'buy':
        if divergence_desc and "åº•èƒŒé©°" in divergence_desc:
            eval_msg = "ğŸ”¥ **æä½³æ“ä½œ (ä¸€ä¹°)**ï¼šæ•æ‰åˆ°åº•èƒŒé©°ï¼Œæ˜¯ç¼ è®ºå®šä¹‰çš„ç¬¬ä¸€ç±»ä¹°ç‚¹ï¼"
            score = 1
        elif fenxing == 'bottom' and trend == 'å¤šå¤´':
            eval_msg = "âœ… **åˆç†æ“ä½œ (äºŒä¹°/ä¸‰ä¹°)**ï¼šå¤šå¤´è¶‹åŠ¿å›è°ƒå‡ºç°çš„åº•åˆ†å‹ï¼Œç¡®è®¤ä¸ºæ¬¡çº§åˆ«è°ƒæ•´ç»“æŸã€‚"
            score = 1
        elif fenxing == 'bottom':
            eval_msg = "âš ï¸ **æ¿€è¿›æ“ä½œ**ï¼šç©ºå¤´è¶‹åŠ¿ä¸‹çš„åº•åˆ†å‹ï¼Œè‹¥æ— å¤§çº§åˆ«èƒŒé©°æ”¯æŒï¼Œæå¯èƒ½æ˜¯ä¸‹è·Œä¸­ç»§ã€‚"
            score = 0
        elif hist > 0 and hist > hist_prev:
            eval_msg = "âš ï¸ **è¿½æ¶¨é£é™©**ï¼šçº¢æŸ±åŠ é€Ÿä¼¸é•¿æ—¶ä¹°å…¥ï¼Œæ˜“ä¹°åœ¨ç¬”çš„é¡¶éƒ¨ï¼Œéç¼ è®ºç²¾ç¡®ä¹°ç‚¹ï¼ˆåº”åœ¨ç»¿æŸ±ç¼©çŸ­æˆ–çº¢æŸ±å›æŠ½æ—¶å…³æ³¨ï¼‰ã€‚"
            score = 0
        else:
            eval_msg = "âŒ **æ— æ•ˆæ“ä½œ**ï¼šå½“å‰æ— ç»“æ„æ”¯æŒï¼ˆæ— åº•åˆ†å‹ã€æ— èƒŒé©°ï¼‰ï¼Œå±äºç›²ç›®äº¤æ˜“ã€‚"
            score = -1
            
    elif action == 'sell':
        if divergence_desc and "é¡¶èƒŒé©°" in divergence_desc:
            eval_msg = "ğŸ”¥ **æä½³æ“ä½œ (ä¸€å–)**ï¼šæ•æ‰åˆ°é¡¶èƒŒé©°ï¼Œæ˜¯ç¼ è®ºå®šä¹‰çš„ç¬¬ä¸€ç±»å–ç‚¹ï¼"
            score = 1
        elif fenxing == 'top' and trend == 'ç©ºå¤´':
            eval_msg = "âœ… **åˆç†æ“ä½œ (äºŒå–/ä¸‰å–)**ï¼šç©ºå¤´è¶‹åŠ¿åå¼¹å‡ºç°çš„é¡¶åˆ†å‹ï¼Œç¡®è®¤ä¸ºä¸‹è·Œä¸­ç»§ã€‚"
            score = 1
        elif fenxing == 'top':
            eval_msg = "âš ï¸ **è°¨æ…æ“ä½œ**ï¼šå¤šå¤´è¶‹åŠ¿ä¸­çš„é¡¶åˆ†å‹ï¼Œå¯èƒ½æ˜¯ä¸Šæ¶¨ä¸­ç»§ï¼Œä»…é€‚åˆçŸ­å·®å‡ä»“ã€‚"
            score = 0
        elif hist < 0 and hist < hist_prev:
            eval_msg = "âš ï¸ **æ€è·Œé£é™©**ï¼šç»¿æŸ±åŠ é€Ÿä¼¸é•¿æ—¶å–å‡ºå¾€å¾€æ»åï¼Œæ˜“å–åœ¨ä½ä½ï¼Œåº”åœ¨çº¢æŸ±ç¼©çŸ­æˆ–èƒŒé©°æ—¶ç¦»åœºã€‚"
            score = 0
        else:
            eval_msg = "âŒ **æ— æ•ˆæ“ä½œ**ï¼šå½“å‰æ— ç»“æ„æ”¯æŒï¼ˆæ— é¡¶åˆ†å‹ã€æ— èƒŒé©°ï¼‰ï¼Œå±äºææ…Œæ€§æˆ–éšæ„æŠ›å”®ã€‚"
            score = -1
            
    elif action == 'hold':
        if divergence_desc and "åº•èƒŒé©°" in divergence_desc:
            eval_msg = "âŒ **é”™å¤±è‰¯æœº**ï¼šå½“å‰å‡ºç°åº•èƒŒé©°ä¸€ä¹°ä¿¡å·ï¼Œç†åº”å°è¯•å»ºä»“ã€‚"
            score = -1
        elif divergence_desc and "é¡¶èƒŒé©°" in divergence_desc:
            eval_msg = "âš ï¸ **é£é™©æç¤º**ï¼šå½“å‰å‡ºç°é¡¶èƒŒé©°ä¸€å–ä¿¡å·ï¼Œå»ºè®®å‡ä»“æˆ–ç¦»åœºã€‚"
            score = -1
        elif fenxing == 'bottom' and trend == 'å¤šå¤´':
            eval_msg = "â„¹ï¸ **å…³æ³¨æœºä¼š**ï¼šå¤šå¤´å›è°ƒå‡ºç°åº•åˆ†å‹ï¼Œæ˜¯æ½œåœ¨ä¹°ç‚¹ï¼Œè§‚æœ›å¯èƒ½è¸ç©ºã€‚"
            score = 0
        elif fenxing == 'top' and trend == 'ç©ºå¤´':
            eval_msg = "â„¹ï¸ **å…³æ³¨é£é™©**ï¼šç©ºå¤´åå¼¹å‡ºç°é¡¶åˆ†å‹ï¼Œæ˜¯æ½œåœ¨å–ç‚¹ï¼Œè§‚æœ›å¯èƒ½åè¿‡å±±è½¦ã€‚"
            score = 0
        else:
            eval_msg = "â˜• **åˆç†è§‚æœ›**ï¼šèµ°åŠ¿å»¶ç»­ä¸­æˆ–æ— æ˜ç¡®ä¿¡å·ï¼ŒæŒä»“/æŒå¸ä¸åŠ¨æ˜¯æ˜æ™ºçš„ï¼ˆç¼ è®ºè®²ç©¶â€œä¸æ‚£â€ï¼‰ã€‚"
            score = 1

    msg.append(eval_msg)
    
    return "\n\n".join(msg), score, highlight_shapes

def analyze_advanced_action(action, current_idx, day_data, day_macd, week_data, week_macd, month_data, month_macd):
    """
    é«˜çº§æ¨¡å¼åˆ†æï¼Œç»“åˆæ—¥ã€å‘¨ã€æœˆçº¿
    """
    # 1. åŸºç¡€æ—¥çº¿åˆ†æ
    day_msg, day_score, day_shapes = analyze_action(action, day_data, day_macd, current_idx)
    
    # 2. å¯»æ‰¾å¯¹åº”çš„å‘¨ã€æœˆçº¿ç´¢å¼•
    c_time = day_data[current_idx]['time'] # current day index/time
    
    # æ‰¾åˆ°åŒ…å« c_time çš„å‘¨Kçº¿
    week_idx = -1
    for i, w in enumerate(week_data):
        if w['start_day_idx'] <= c_time <= w['end_day_idx']:
            week_idx = i
            break
            
    # æ‰¾åˆ°åŒ…å« c_time çš„æœˆKçº¿
    month_idx = -1
    for i, m in enumerate(month_data):
        if m['start_day_idx'] <= c_time <= m['end_day_idx']:
            month_idx = i
            break
            
    adv_msg = []
    
    # åˆ†æå¤§çº§åˆ«è¶‹åŠ¿
    week_trend = "æ— "
    week_details = []
    if week_idx >= 0:
        w_closes = [k['close'] for k in week_data[:week_idx+1]]
        w_ma5 = sum(w_closes[-5:]) / len(w_closes[-5:]) if len(w_closes)>=5 else w_closes[-1]
        w_ma20 = sum(w_closes[-20:]) / len(w_closes[-20:]) if len(w_closes)>=20 else w_closes[-1]
        week_trend = "å¤šå¤´" if w_ma5 > w_ma20 else "ç©ºå¤´"
        
        # ç®€å•åˆ¤æ–­å‘¨çº¿åˆ†å‹
        w_fenxing = identify_fenxing(week_data[:week_idx+1])
        if w_fenxing == 'top': week_details.append("å‘¨çº¿é¡¶åˆ†å‹")
        elif w_fenxing == 'bottom': week_details.append("å‘¨çº¿åº•åˆ†å‹")

    month_trend = "æ— "
    if month_idx >= 0:
        m_closes = [k['close'] for k in month_data[:month_idx+1]]
        m_ma5 = sum(m_closes[-5:]) / len(m_closes[-5:]) if len(m_closes)>=5 else m_closes[-1]
        m_ma20 = sum(m_closes[-20:]) / len(m_closes[-20:]) if len(m_closes)>=20 else m_closes[-1]
        month_trend = "å¤šå¤´" if m_ma5 > m_ma20 else "ç©ºå¤´"

    # ç”Ÿæˆå…±æŒ¯è¯„ä»·
    resonance_msg = f"**å¤§çº§åˆ«é…åˆ**: å‘¨çº¿{week_trend} ({', '.join(week_details)})ï¼Œæœˆçº¿{month_trend}ã€‚" if week_details else f"**å¤§çº§åˆ«é…åˆ**: å‘¨çº¿{week_trend}ï¼Œæœˆçº¿{month_trend}ã€‚"
    
    bonus_score = 0
    
    if action == 'buy':
        if week_trend == 'å¤šå¤´':
            resonance_msg += " (å‘¨çº¿é¡ºåŠ¿ï¼ŒåŠ åˆ†)"
            bonus_score += 1
        elif week_trend == 'ç©ºå¤´':
            resonance_msg += " (å‘¨çº¿é€†åŠ¿ï¼Œæ³¨æ„å¿«è¿›å¿«å‡º)"
            
        # æ£€æŸ¥å‘¨çº¿åº•èƒŒé©°
        if week_idx > 10:
            w_div_desc, _ = check_divergence(week_data, week_macd, week_idx, lookback=10)
            if w_div_desc and "åº•èƒŒé©°" in w_div_desc:
                resonance_msg += " ğŸ”¥å‘¨çº¿åº•èƒŒé©°å…±æŒ¯ï¼"
                bonus_score += 2

    elif action == 'sell':
        if week_trend == 'ç©ºå¤´':
            resonance_msg += " (å‘¨çº¿é¡ºåŠ¿ä¸‹è·Œï¼ŒåŠ åˆ†)"
            bonus_score += 1
        
        if week_idx > 10:
            w_div_desc, _ = check_divergence(week_data, week_macd, week_idx, lookback=10)
            if w_div_desc and "é¡¶èƒŒé©°" in w_div_desc:
                resonance_msg += " ğŸ”¥å‘¨çº¿é¡¶èƒŒé©°å…±æŒ¯ï¼"
                bonus_score += 2
    
    final_msg = f"{day_msg}\n\n{resonance_msg}"
    
    return final_msg, day_score, day_shapes
